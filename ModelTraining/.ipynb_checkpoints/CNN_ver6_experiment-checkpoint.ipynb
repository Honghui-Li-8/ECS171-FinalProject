{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======done load======\n",
      "(3410, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset = pd.read_csv('archive/english.csv')\n",
    "directory = \"archive\"\n",
    "\n",
    "imageDatas = []\n",
    "files = dataset[\"image\"]\n",
    "label = dataset[\"label\"]\n",
    "dimention = \"100x100\"\n",
    "npzFileName = \"Uncompressed_\" + dimention + \".npz\"\n",
    "\n",
    "# Load  compressed image matrix data\n",
    "data = np.load(npzFileName)\n",
    "ImageData_compressed = data['imageDatas_np']\n",
    "print(\"=======done load======\")\n",
    "\n",
    "print(ImageData_compressed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### 1) center the char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerChar(Img):\n",
    "    dimension = len(Img)\n",
    "    location = locatChar(Img)\n",
    "    \n",
    "    resultImg = []\n",
    "    for i in range(dimension):\n",
    "        row = []\n",
    "        for j in range(dimension):\n",
    "            row += [[np.float32(1.0)]]\n",
    "            \n",
    "        resultImg += [row]\n",
    "    \n",
    "    offset_row = int((dimension-(location[1] + 1 -location[0]))/2)    \n",
    "    offset_col = int((dimension-(location[3] + 1 -location[2]))/2)\n",
    "    \n",
    "    for i in range(0, location[1] + 1 - location[0]):\n",
    "        for j in range(0, location[3] + 1 - location[2]):\n",
    "            resultImg[i + offset_row][j + offset_col][0] = Img[i + location[0]][j + location[2]][0]\n",
    "    \n",
    "    \n",
    "    resultImg = np.array(resultImg)\n",
    "    return resultImg\n",
    "    \n",
    "def locatChar(Img):\n",
    "    dimension = len(Img)\n",
    "    top = dimension\n",
    "    bottom = 0\n",
    "    left = dimension\n",
    "    right = 0\n",
    "    \n",
    "    for i in range(dimension):\n",
    "        for j in range(dimension):\n",
    "            if Img[i][j][0] < 0.2:\n",
    "                if top > i:\n",
    "                    top = i\n",
    "                if bottom < i:\n",
    "                    bottom = i\n",
    "                if left > j:\n",
    "                    left = j\n",
    "                if right < j:\n",
    "                    right = j\n",
    "    return [top, bottom, left, right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = centerChar(ImageData_compressed[0])\n",
    "plt.imshow(ImageData_compressed[0])\n",
    "plt.show()\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "\n",
    "portion = (ImageData_compressed[0])[17:82, 19:54]\n",
    "# plt.imshow(portion)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====start processing=====\n",
      "processed:  500  imgs\n",
      "processed:  1000  imgs\n",
      "processed:  1500  imgs\n",
      "processed:  2000  imgs\n",
      "processed:  2500  imgs\n",
      "processed:  3000  imgs\n",
      "=====finish processing=====\n",
      "(3410, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# center all the data\n",
    "\n",
    "ImageData_centered = []\n",
    "count = 0\n",
    "print(\"=====start processing=====\")\n",
    "for img in ImageData_compressed:\n",
    "    img_c = centerChar(img)\n",
    "    ImageData_centered += [img_c]\n",
    "    \n",
    "    count += 1\n",
    "    if (count % 500 == 0):\n",
    "        print(\"processed: \", count, \" imgs\" )\n",
    "\n",
    "print(\"=====finish processing=====\")\n",
    "\n",
    "ImageData_centered = np.array(ImageData_centered)\n",
    "print(ImageData_centered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "dimention = \"100x100\"\n",
    "npzFileName = \"Centered_\" + dimention + \".npz\"\n",
    "\n",
    "# Save compressed data to NPZ file\n",
    "# numpy.savez(npzFileName, ImageData_centered=ImageData_centered)\n",
    "# print(\"=======done saving======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======done loading=======\n",
      "(3410, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('archive/english.csv')\n",
    "directory = \"archive\"\n",
    "\n",
    "imageDatas = []\n",
    "files = dataset[\"image\"]\n",
    "label = dataset[\"label\"]\n",
    "dimention = \"100x100\"\n",
    "npzFileName = \"Centered_\" + dimention + \".npz\"\n",
    "\n",
    "# Load  compressed image matrix data\n",
    "data = numpy.load(npzFileName)\n",
    "ImageData_centered = data['ImageData_centered']\n",
    "print(\"=======done loading=======\")\n",
    "\n",
    "print(ImageData_centered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGgCAYAAADsNrNZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZT0lEQVR4nO3df2yV5f3/8Vd/0NMq7SkUe9qOFqrBFAEjUigFsl80I45sMDo3krrVHxlTi1JIRLpZlk2hwBJlMIVBNqYZyCQZKCTDkOKaEMuvOphMKSzwGY14DprZcypIIT3X9w+/nngElFMOvM9pn4/kJPY+9zm9ehnOM9d9n3OfFOecEwAAN1iq9QAAAP0TAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJi4bgF6/vnnNXz4cGVmZqqiokL79++/Xr8KAJCEUq7HteD++te/6qc//anWrl2riooKrVy5Ulu2bFF7e7vy8/O/9LHhcFinT59Wdna2UlJS4j00AMB15pxTV1eXioqKlJr6Jescdx1MmDDB1dXVRX7u6elxRUVFrqmp6Ssf29HR4SRx48aNG7ckv3V0dHzp63264uzChQtqa2tTQ0NDZFtqaqqqqqrU2tp6yf7d3d3q7u6O/Oz+/4Lsv28NV85ATlEBQLIJfRzWsLv/T9nZ2V+6X9wD9OGHH6qnp0c+ny9qu8/n09GjRy/Zv6mpSb/+9a8v2Z4zMFU52QQIAJLVV51GMX+Fb2hoUDAYjNw6OjqshwQAuAHivgIaMmSI0tLSFAgEorYHAgEVFBRcsr/H45HH44n3MAAACS7uK6CMjAyNGzdOzc3NkW3hcFjNzc2qrKyM968DACSpuK+AJGnBggWqra1VeXm5JkyYoJUrV+rs2bN64IEHrsevAwAkoesSoB//+Mf64IMPtHjxYvn9ft11113auXPnJW9MAAD0X9flg6jXIhQKyev16qNjt/IuOABIQqGusAbdfkLBYFA5OTlX3I9XeACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAipgA1NTVp/Pjxys7OVn5+vmbOnKn29vaofc6fP6+6ujrl5eVp4MCBqq6uViAQiOugAQDJL6YAtbS0qK6uTnv37tWuXbt08eJFfec739HZs2cj+8yfP1/bt2/Xli1b1NLSotOnT2vWrFlxHzgAILmlOOdcbx/8wQcfKD8/Xy0tLfr617+uYDCoW265RZs2bdIPf/hDSdLRo0c1cuRItba2auLEiZc8R3d3t7q7uyM/h0IhFRcX66NjtyonmyOEAJBsQl1hDbr9hILBoHJycq643zW9wgeDQUnS4MGDJUltbW26ePGiqqqqIvuUlZWppKREra2tl32OpqYmeb3eyK24uPhahgQASBK9DlA4HFZ9fb0mT56s0aNHS5L8fr8yMjKUm5sbta/P55Pf77/s8zQ0NCgYDEZuHR0dvR0SACCJpPf2gXV1dTpy5Ij27NlzTQPweDzyeDzX9BwAgOTTqxXQ3LlztWPHDr3xxhsaOnRoZHtBQYEuXLigzs7OqP0DgYAKCgquaaAAgL4lpgA55zR37lxt3bpVu3fvVmlpadT948aN04ABA9Tc3BzZ1t7erlOnTqmysjI+IwYA9AkxHYKrq6vTpk2b9Oqrryo7OztyXsfr9SorK0ter1cPPfSQFixYoMGDBysnJ0ePPfaYKisrL/sOOABA/xVTgNasWSNJ+uY3vxm1fcOGDbr//vslSc8995xSU1NVXV2t7u5uTZs2TS+88EJcBgsA6Duu6XNA10MoFJLX6+VzQACQpG7I54AAAOgtAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz0+mrYAJBIphXdddX7vn760HUbB64eKyAAgAkCBAAwQYAAACY4BwQgKcVyzuerHss5IRusgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAk+BwQgaVzLZ3+QeFgBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJLsUDoN/hK7gTAysgAIAJAgQAMMEhOAAJi6tf922sgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABJfiAZAwrteld7j6dWJiBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEzwOSAA/U4snzfiM0TXDysgAIAJAgQAMEGAAAAmOAcEwNSNuP7btfyOLz6Wc0LxwwoIAGCCAAEATHAIDkCfdL0O7SF+WAEBAEwQIACAiWsK0LJly5SSkqL6+vrItvPnz6uurk55eXkaOHCgqqurFQgErnWcAIA+ptcBOnDggP7whz/ozjvvjNo+f/58bd++XVu2bFFLS4tOnz6tWbNmXfNAAQB9S68C9PHHH6umpkbr16/XoEGDItuDwaD++Mc/6tlnn9W3v/1tjRs3Ths2bNCbb76pvXv3Xva5uru7FQqFom4AgL6vVwGqq6vT9OnTVVVVFbW9ra1NFy9ejNpeVlamkpIStba2Xva5mpqa5PV6I7fi4uLeDAkAkGRiDtDmzZv11ltvqamp6ZL7/H6/MjIylJubG7Xd5/PJ7/df9vkaGhoUDAYjt46OjliHBABIQjF9Dqijo0Pz5s3Trl27lJmZGZcBeDweeTyeuDwXACB5xLQCamtr05kzZ3T33XcrPT1d6enpamlp0apVq5Seni6fz6cLFy6os7Mz6nGBQEAFBQXxHDcAIMnFtAKaOnWq3n777ahtDzzwgMrKyvTkk0+quLhYAwYMUHNzs6qrqyVJ7e3tOnXqlCorK+M3agBA0ospQNnZ2Ro9enTUtptvvll5eXmR7Q899JAWLFigwYMHKycnR4899pgqKys1ceLE+I0aQNJKtkvkcPXr6yfu14J77rnnlJqaqurqanV3d2vatGl64YUX4v1rAABJLsU556wH8XmhUEher1cfHbtVOdlcKQjoa1gB9X2hrrAG3X5CwWBQOTk5V9yPV3gAgAkCBAAwQYAAACYIEADABAECAJjgK7kB4At459uNwQoIAGCCAAEATHAIDkC/xyE3G6yAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACT4HBKDf4XM/iYEVEADABAECAJggQAAAE5wDAtDncc4nMbECAgCYIEAAABMcggNwXU0rusvk93LYLfGxAgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb4HBCAPoHP/SQfVkAAABMECABggkNwAPqEWC75w+G6xMAKCABgggABAEwQIACACc4BAeh3OF+UGFgBAQBMECAAgAkCBAAwwTkgAPgSXzxfxDmh+GEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBQPgLiK5asO0L+xAgIAmCBAAAATBAgAYIJzQACSxue/CoFzTcmPFRAAwAQBAgCY4BAcgKT0Vd9MGq9DdHwD6vXDCggAYIIAAQBMxByg9957T/fdd5/y8vKUlZWlMWPG6ODBg5H7nXNavHixCgsLlZWVpaqqKh0/fjyugwYAJL+YzgF99NFHmjx5sr71rW/p73//u2655RYdP35cgwYNiuyzYsUKrVq1Si+++KJKS0vV2NioadOm6Z133lFmZmbc/wAAieWL50ys3i7NuZvEF1OAli9fruLiYm3YsCGyrbS0NPLfzjmtXLlSTz31lGbMmCFJeumll+Tz+bRt2zbNnj37kufs7u5Wd3d35OdQKBTzHwEASD4xHYJ77bXXVF5ernvvvVf5+fkaO3as1q9fH7n/5MmT8vv9qqqqimzzer2qqKhQa2vrZZ+zqalJXq83cisuLu7lnwIASCYxBejEiRNas2aNRowYoddff12PPPKIHn/8cb344ouSJL/fL0ny+XxRj/P5fJH7vqihoUHBYDBy6+jo6M3fAQBIMjEdgguHwyovL9fSpUslSWPHjtWRI0e0du1a1dbW9moAHo9HHo+nV48F0LdxHqdvi2kFVFhYqDvuuCNq28iRI3Xq1ClJUkFBgSQpEAhE7RMIBCL3AQAgxRigyZMnq729PWrbsWPHNGzYMEmfviGhoKBAzc3NkftDoZD27dunysrKOAwXANBXxHQIbv78+Zo0aZKWLl2qH/3oR9q/f7/WrVundevWSZJSUlJUX1+vZ555RiNGjIi8DbuoqEgzZ868HuMHkOBieVs2h9z6l5gCNH78eG3dulUNDQ36zW9+o9LSUq1cuVI1NTWRfRYuXKizZ89qzpw56uzs1JQpU7Rz504+AwQAiJLinHPWg/i8UCgkr9erj47dqpxsrhQE9DWsgPq+UFdYg24/oWAwqJycnCvuxys8AMAEX8cA4IZilYPPsAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiZgC1NPTo8bGRpWWliorK0u33Xabnn76aTnnIvs457R48WIVFhYqKytLVVVVOn78eNwHDgBIbjEFaPny5VqzZo1+//vf691339Xy5cu1YsUKrV69OrLPihUrtGrVKq1du1b79u3TzTffrGnTpun8+fNxHzwAIHmlx7Lzm2++qRkzZmj69OmSpOHDh+vll1/W/v37JX26+lm5cqWeeuopzZgxQ5L00ksvyefzadu2bZo9e/Ylz9nd3a3u7u7Iz6FQqNd/DAAgecS0Apo0aZKam5t17NgxSdLhw4e1Z88e3XPPPZKkkydPyu/3q6qqKvIYr9eriooKtba2XvY5m5qa5PV6I7fi4uLe/i0AgCQS0wpo0aJFCoVCKisrU1pamnp6erRkyRLV1NRIkvx+vyTJ5/NFPc7n80Xu+6KGhgYtWLAg8nMoFCJCANAPxBSgV155RRs3btSmTZs0atQoHTp0SPX19SoqKlJtbW2vBuDxeOTxeHr1WABA8oopQE888YQWLVoUOZczZswY/fe//1VTU5Nqa2tVUFAgSQoEAiosLIw8LhAI6K677orfqAEASS+mc0Dnzp1Tamr0Q9LS0hQOhyVJpaWlKigoUHNzc+T+UCikffv2qbKyMg7DBQD0FTGtgL73ve9pyZIlKikp0ahRo/TPf/5Tzz77rB588EFJUkpKiurr6/XMM89oxIgRKi0tVWNjo4qKijRz5szrMX4AQJKKKUCrV69WY2OjHn30UZ05c0ZFRUX6+c9/rsWLF0f2Wbhwoc6ePas5c+aos7NTU6ZM0c6dO5WZmRn3wQMAkleK+/xlDBJAKBSS1+vVR8duVU42VwoCgGQT6gpr0O0nFAwGlZOTc8X9eIUHAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJtKtB/BFzjlJUujjsPFIAAC98dnr92ev51eScAHq6uqSJA27+/9sBwIAuCZdXV3yer1XvD/FfVWibrBwOKzTp0/LOaeSkhJ1dHQoJyfHelgJKxQKqbi4mHn6CszT1WGerg7z9OWcc+rq6lJRUZFSU698pifhVkCpqakaOnSoQqGQJCknJ4f/wVeBebo6zNPVYZ6uDvN0ZV+28vkMb0IAAJggQAAAEwkbII/Ho1/96lfyeDzWQ0lozNPVYZ6uDvN0dZin+Ei4NyEAAPqHhF0BAQD6NgIEADBBgAAAJggQAMAEAQIAmEjYAD3//PMaPny4MjMzVVFRof3791sPyUxTU5PGjx+v7Oxs5efna+bMmWpvb4/a5/z586qrq1NeXp4GDhyo6upqBQIBoxEnhmXLliklJUX19fWRbczTp9577z3dd999ysvLU1ZWlsaMGaODBw9G7nfOafHixSosLFRWVpaqqqp0/PhxwxHfeD09PWpsbFRpaamysrJ022236emnn466wCbzdI1cAtq8ebPLyMhwf/rTn9y///1v97Of/czl5ua6QCBgPTQT06ZNcxs2bHBHjhxxhw4dct/97nddSUmJ+/jjjyP7PPzww664uNg1Nze7gwcPuokTJ7pJkyYZjtrW/v373fDhw92dd97p5s2bF9nOPDn3v//9zw0bNszdf//9bt++fe7EiRPu9ddfd//5z38i+yxbtsx5vV63bds2d/jwYff973/flZaWuk8++cRw5DfWkiVLXF5entuxY4c7efKk27Jlixs4cKD73e9+F9mHebo2CRmgCRMmuLq6usjPPT09rqioyDU1NRmOKnGcOXPGSXItLS3OOec6OzvdgAED3JYtWyL7vPvuu06Sa21ttRqmma6uLjdixAi3a9cu941vfCMSIObpU08++aSbMmXKFe8Ph8OuoKDA/fa3v41s6+zsdB6Px7388ss3YogJYfr06e7BBx+M2jZr1ixXU1PjnGOe4iHhDsFduHBBbW1tqqqqimxLTU1VVVWVWltbDUeWOILBoCRp8ODBkqS2tjZdvHgxas7KyspUUlLSL+esrq5O06dPj5oPiXn6zGuvvaby8nLde++9ys/P19ixY7V+/frI/SdPnpTf74+aJ6/Xq4qKin41T5MmTVJzc7OOHTsmSTp8+LD27Nmje+65RxLzFA8JdzXsDz/8UD09PfL5fFHbfT6fjh49ajSqxBEOh1VfX6/Jkydr9OjRkiS/36+MjAzl5uZG7evz+eT3+w1GaWfz5s166623dODAgUvuY54+deLECa1Zs0YLFizQL37xCx04cECPP/64MjIyVFtbG5mLy/0b7E/ztGjRIoVCIZWVlSktLU09PT1asmSJampqJIl5ioOECxC+XF1dnY4cOaI9e/ZYDyXhdHR0aN68edq1a5cyMzOth5OwwuGwysvLtXTpUknS2LFjdeTIEa1du1a1tbXGo0scr7zyijZu3KhNmzZp1KhROnTokOrr61VUVMQ8xUnCHYIbMmSI0tLSLnlnUiAQUEFBgdGoEsPcuXO1Y8cOvfHGGxo6dGhke0FBgS5cuKDOzs6o/fvbnLW1tenMmTO6++67lZ6ervT0dLW0tGjVqlVKT0+Xz+djniQVFhbqjjvuiNo2cuRInTp1SpIic9Hf/w0+8cQTWrRokWbPnq0xY8boJz/5iebPn6+mpiZJzFM8JFyAMjIyNG7cODU3N0e2hcNhNTc3q7Ky0nBkdpxzmjt3rrZu3ardu3ertLQ06v5x48ZpwIABUXPW3t6uU6dO9as5mzp1qt5++20dOnQocisvL1dNTU3kv5knafLkyZe8jf/YsWMaNmyYJKm0tFQFBQVR8xQKhbRv375+NU/nzp275Ns809LSFA6HJTFPcWH9LojL2bx5s/N4PO7Pf/6ze+edd9ycOXNcbm6u8/v91kMz8cgjjziv1+v+8Y9/uPfffz9yO3fuXGSfhx9+2JWUlLjdu3e7gwcPusrKSldZWWk46sTw+XfBOcc8OffpW9TT09PdkiVL3PHjx93GjRvdTTfd5P7yl79E9lm2bJnLzc11r776qvvXv/7lZsyY0e/eXlxbW+u+9rWvRd6G/be//c0NGTLELVy4MLIP83RtEjJAzjm3evVqV1JS4jIyMtyECRPc3r17rYdkRtJlbxs2bIjs88knn7hHH33UDRo0yN10003uBz/4gXv//fftBp0gvhgg5ulT27dvd6NHj3Yej8eVlZW5devWRd0fDoddY2Oj8/l8zuPxuKlTp7r29naj0doIhUJu3rx5rqSkxGVmZrpbb73V/fKXv3Td3d2RfZina8P3AQEATCTcOSAAQP9AgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxP8DtMh8HFKHLS0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ImageData_compressed[2578])\n",
    "plt.show()\n",
    "plt.imshow(ImageData_centered[2578])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndex(letter):\n",
    "    index = ord(letter)-48\n",
    "    if (index > 10):\n",
    "        index -= 7\n",
    "    if (index > 35):\n",
    "        index -= 6\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3410,)\n",
      "(620,)\n",
      "(2790, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data_nparr = ImageData_centered\n",
    "label_nparr = np.array(label)\n",
    "\n",
    "test_index = []\n",
    "# Randomly select 6 items from each group of 55\n",
    "selected_indices = []\n",
    "print(label_nparr.shape)\n",
    "for i in range(0, len(label_nparr), 55):\n",
    "    charGroup = data_nparr[i:i+55]\n",
    "    indices = random.sample(range(i, i+55), 10)\n",
    "    test_index.extend(indices)\n",
    "\n",
    "test_index_nparr = np.array(test_index)\n",
    "print(test_index_nparr.shape)\n",
    "\n",
    "train_data, test_data, train_label, test_label = [], [], [], []\n",
    "for i in range(len(label_nparr)):\n",
    "    if i in test_index:\n",
    "        test_data += [data_nparr[i]]\n",
    "        test_label += [getIndex(label_nparr[i])]\n",
    "    else:\n",
    "        train_data += [data_nparr[i]]\n",
    "        train_label += [getIndex(label_nparr[i])]\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "train_label = np.array(train_label)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "train_label_onehot = pd.get_dummies(train_label) # one-hot enc\n",
    "test_label_onehot = pd.get_dummies(test_label) # one-hot enc\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "def apply_rotation_augmentation(images):\n",
    "    # Convert the images to TensorFlow tensors\n",
    "    images_tensor = tf.convert_to_tensor(images)\n",
    "\n",
    "    # Reshape the images tensor to (some_amount, height, width, channels)\n",
    "    images_tensor = tf.reshape(images_tensor, [len(images), 100, 100, 1])\n",
    "\n",
    "    # Generate random rotation angles between -5 and 5 degrees for each image\n",
    "    rotation_angles = tf.random.uniform(shape=[len(images)], minval=-10, maxval=10)\n",
    "\n",
    "    # Apply rotation augmentation and resize to each image\n",
    "    rotated_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = tf.keras.preprocessing.image.array_to_img(images_tensor[i])\n",
    "        img = img.rotate(rotation_angles[i])\n",
    "        img = img.resize((116, 116), resample=Image.NEAREST)\n",
    "        img = img.crop((8, 8, 108, 108)) \n",
    "        rotated_img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        rotated_images.append(rotated_img)\n",
    "    \n",
    "    rotated_images = tf.convert_to_tensor(rotated_images)\n",
    "\n",
    "    return rotated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Start Augmentation=============\n",
      "processed  500  Img\n",
      "processed  1000  Img\n",
      "processed  1500  Img\n",
      "processed  2000  Img\n",
      "processed  2500  Img\n",
      "=============Finish Augmentation=============\n",
      "(5580, 100, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data_augmented = train_data\n",
    "print(\"=============Start Augmentation=============\")\n",
    "for i in range(5):\n",
    "    train_data_augmented = np.concatenate((train_data_augmented, apply_rotation_augmentation(train_data[i * 500:(i + 1) * 500])), axis=0)\n",
    "    print(\"processed \", (i + 1) * 500, \" Img\")\n",
    "    \n",
    "train_data_augmented = np.concatenate((train_data_augmented, apply_rotation_augmentation(train_data[2500:2790])), axis=0)\n",
    "print(\"=============Finish Augmentation=============\")\n",
    "print(train_data_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2790,)\n",
      "(5580, 62)\n"
     ]
    }
   ],
   "source": [
    "train_label_augmented = np.concatenate((train_label, train_label), axis=0)\n",
    "train_label_augmented_onehot = pd.get_dummies(train_label_augmented)\n",
    "print(train_label.shape)\n",
    "print(train_label_augmented_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_check = 1000;\n",
    "plt.imshow(train_data_augmented[index_check])\n",
    "plt.show()\n",
    "plt.imshow(train_data_augmented[index_check + 2790])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====function made=====\n"
     ]
    }
   ],
   "source": [
    "def create_model(kernel_size1 = 3, kernel_size2 = 3, regulazation_p = 0.01, dense_node = 128, drop_out_rate = 0.1):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (kernel_size1, kernel_size1), activation='relu', input_shape=data_nparr[0].shape, kernel_regularizer=regularizers.l2(regulazation_p)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (kernel_size2, kernel_size2), activation='relu', kernel_regularizer=regularizers.l2(regulazation_p)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(regulazation_p)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(dense_node, activation='relu', kernel_regularizer=regularizers.l2(regulazation_p)))\n",
    "    model.add(layers.Dropout(drop_out_rate))\n",
    "    model.add(layers.Dense(62, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"====function made=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}\n",
      "Best Accuracy:  0.8080645203590393\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and accuracy for 64 dense node\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_node': 256, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}\n",
      "Best Accuracy:  0.7983871102333069\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters and accuracy for 64, 128, 256 dense node\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========started grid search============\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 6.8732 - accuracy: 0.0199 - val_loss: 5.4096 - val_accuracy: 0.0516\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 4.8074 - accuracy: 0.1287 - val_loss: 4.6530 - val_accuracy: 0.1339\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 3.2241 - accuracy: 0.3849 - val_loss: 2.7777 - val_accuracy: 0.4952\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 2.3601 - accuracy: 0.5686 - val_loss: 2.3139 - val_accuracy: 0.5774\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 1.9764 - accuracy: 0.6333 - val_loss: 1.9800 - val_accuracy: 0.6403\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 1.6959 - accuracy: 0.6835 - val_loss: 1.8257 - val_accuracy: 0.6839\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 1.5715 - accuracy: 0.7111 - val_loss: 1.7635 - val_accuracy: 0.6806\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 1.4428 - accuracy: 0.7403 - val_loss: 1.5736 - val_accuracy: 0.7306\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 1.3589 - accuracy: 0.7478 - val_loss: 1.5384 - val_accuracy: 0.7274\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 1.2706 - accuracy: 0.7608 - val_loss: 1.4483 - val_accuracy: 0.7290\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 1.1953 - accuracy: 0.7805 - val_loss: 1.4229 - val_accuracy: 0.7403\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 1.1494 - accuracy: 0.7909 - val_loss: 1.3635 - val_accuracy: 0.7081\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 1.0959 - accuracy: 0.7943 - val_loss: 1.3586 - val_accuracy: 0.7435\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.0881 - accuracy: 0.7975 - val_loss: 1.3428 - val_accuracy: 0.7484\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.0205 - accuracy: 0.8158 - val_loss: 1.3267 - val_accuracy: 0.7306\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.0290 - accuracy: 0.8050 - val_loss: 1.2792 - val_accuracy: 0.7435\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 0.9720 - accuracy: 0.8124 - val_loss: 1.2481 - val_accuracy: 0.7452\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 0.9786 - accuracy: 0.8120 - val_loss: 1.2431 - val_accuracy: 0.7629\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 0.9282 - accuracy: 0.8242 - val_loss: 1.2097 - val_accuracy: 0.7613\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 20s 114ms/step - loss: 0.9332 - accuracy: 0.8151 - val_loss: 1.2077 - val_accuracy: 0.7645\n",
      "current best accuracy 0.7645161151885986\n",
      "updated best\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 11s 117ms/step - loss: 4.5704 - accuracy: 0.0333 - val_loss: 3.8121 - val_accuracy: 0.1048\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 3.2122 - accuracy: 0.2330 - val_loss: 2.6439 - val_accuracy: 0.3919\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 10s 116ms/step - loss: 2.4585 - accuracy: 0.4197 - val_loss: 2.1449 - val_accuracy: 0.5371\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 2.0250 - accuracy: 0.5312 - val_loss: 1.8603 - val_accuracy: 0.5887\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 1.7642 - accuracy: 0.6090 - val_loss: 1.7159 - val_accuracy: 0.6258\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 1.5914 - accuracy: 0.6588 - val_loss: 1.5641 - val_accuracy: 0.6919\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 1.4524 - accuracy: 0.6839 - val_loss: 1.5673 - val_accuracy: 0.6984\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 1.3575 - accuracy: 0.7168 - val_loss: 1.4127 - val_accuracy: 0.7274\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 1.2682 - accuracy: 0.7452 - val_loss: 1.4359 - val_accuracy: 0.7226\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 1.2052 - accuracy: 0.7581 - val_loss: 1.4446 - val_accuracy: 0.7452\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 1.1601 - accuracy: 0.7713 - val_loss: 1.3925 - val_accuracy: 0.7290\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 1.1332 - accuracy: 0.7799 - val_loss: 1.3305 - val_accuracy: 0.7661\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.0647 - accuracy: 0.8082 - val_loss: 1.3561 - val_accuracy: 0.7532\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 1.0315 - accuracy: 0.8104 - val_loss: 1.2975 - val_accuracy: 0.7677\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 1.0062 - accuracy: 0.8093 - val_loss: 1.2845 - val_accuracy: 0.7710\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 0.9715 - accuracy: 0.8337 - val_loss: 1.2790 - val_accuracy: 0.7677\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 0.9887 - accuracy: 0.8272 - val_loss: 1.2309 - val_accuracy: 0.7790\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 0.9349 - accuracy: 0.8419 - val_loss: 1.2919 - val_accuracy: 0.7710\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 0.9484 - accuracy: 0.8344 - val_loss: 1.2608 - val_accuracy: 0.7839\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 0.9152 - accuracy: 0.8409 - val_loss: 1.2200 - val_accuracy: 0.7855\n",
      "current best accuracy 0.7854838967323303\n",
      "updated best\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 6.5228 - accuracy: 0.0136 - val_loss: 5.2730 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 5.1219 - accuracy: 0.0113 - val_loss: 4.9916 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 4.9079 - accuracy: 0.0145 - val_loss: 4.8459 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 4.3814 - accuracy: 0.1358 - val_loss: 3.8772 - val_accuracy: 0.1968\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 2.7277 - accuracy: 0.4568 - val_loss: 2.4414 - val_accuracy: 0.5419\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.9951 - accuracy: 0.6281 - val_loss: 2.0446 - val_accuracy: 0.6016\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 20s 114ms/step - loss: 1.7089 - accuracy: 0.6769 - val_loss: 1.8872 - val_accuracy: 0.6532\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 1.5116 - accuracy: 0.7206 - val_loss: 1.7004 - val_accuracy: 0.6952\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.3359 - accuracy: 0.7548 - val_loss: 1.6509 - val_accuracy: 0.6806\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.2679 - accuracy: 0.7685 - val_loss: 1.5694 - val_accuracy: 0.7113\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 1.1663 - accuracy: 0.7952 - val_loss: 1.5009 - val_accuracy: 0.7177\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 1.0987 - accuracy: 0.7996 - val_loss: 1.4255 - val_accuracy: 0.7161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.0451 - accuracy: 0.8106 - val_loss: 1.4383 - val_accuracy: 0.7403\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.0154 - accuracy: 0.8154 - val_loss: 1.3872 - val_accuracy: 0.7242\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 0.9947 - accuracy: 0.8231 - val_loss: 1.3660 - val_accuracy: 0.7484\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 0.9558 - accuracy: 0.8254 - val_loss: 1.3760 - val_accuracy: 0.7371\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 0.9060 - accuracy: 0.8332 - val_loss: 1.3068 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 20s 113ms/step - loss: 0.8849 - accuracy: 0.8400 - val_loss: 1.2402 - val_accuracy: 0.7323\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 0.8564 - accuracy: 0.8410 - val_loss: 1.3154 - val_accuracy: 0.7258\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 20s 114ms/step - loss: 0.8317 - accuracy: 0.8486 - val_loss: 1.2948 - val_accuracy: 0.7290\n",
      "current best accuracy 0.75\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 11s 119ms/step - loss: 4.6443 - accuracy: 0.0168 - val_loss: 4.2194 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 4.1734 - accuracy: 0.0161 - val_loss: 4.1436 - val_accuracy: 0.0242\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 3.9433 - accuracy: 0.0634 - val_loss: 3.5552 - val_accuracy: 0.1419\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 3.2964 - accuracy: 0.1903 - val_loss: 2.8668 - val_accuracy: 0.2774\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 2.8266 - accuracy: 0.2935 - val_loss: 2.5235 - val_accuracy: 0.3823\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 2.5186 - accuracy: 0.3548 - val_loss: 2.2211 - val_accuracy: 0.4355\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 2.3315 - accuracy: 0.4082 - val_loss: 2.0587 - val_accuracy: 0.5081\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 2.1755 - accuracy: 0.4513 - val_loss: 1.9182 - val_accuracy: 0.5355\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 2.0793 - accuracy: 0.4724 - val_loss: 1.8394 - val_accuracy: 0.5581\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 1.9925 - accuracy: 0.4835 - val_loss: 1.7946 - val_accuracy: 0.5629\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.9103 - accuracy: 0.5032 - val_loss: 1.6898 - val_accuracy: 0.5952\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.8517 - accuracy: 0.5258 - val_loss: 1.6360 - val_accuracy: 0.6258\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 1.7713 - accuracy: 0.5394 - val_loss: 1.5942 - val_accuracy: 0.6290\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.7177 - accuracy: 0.5556 - val_loss: 1.6317 - val_accuracy: 0.6161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.7000 - accuracy: 0.5695 - val_loss: 1.5491 - val_accuracy: 0.6403\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 1.6436 - accuracy: 0.5832 - val_loss: 1.5231 - val_accuracy: 0.6565\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.6177 - accuracy: 0.5796 - val_loss: 1.4918 - val_accuracy: 0.6613\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.6084 - accuracy: 0.5943 - val_loss: 1.5123 - val_accuracy: 0.6694\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 1.5296 - accuracy: 0.6036 - val_loss: 1.4699 - val_accuracy: 0.6629\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 1.5118 - accuracy: 0.6251 - val_loss: 1.4393 - val_accuracy: 0.6742\n",
      "current best accuracy 0.6741935610771179\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 6.9981 - accuracy: 0.0136 - val_loss: 5.7254 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 5.4730 - accuracy: 0.0125 - val_loss: 5.2617 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 5.1151 - accuracy: 0.0131 - val_loss: 4.9848 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 4.8866 - accuracy: 0.0134 - val_loss: 4.7959 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.7243 - accuracy: 0.0099 - val_loss: 4.6567 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 4.6120 - accuracy: 0.0159 - val_loss: 4.5706 - val_accuracy: 0.0210\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 4.4338 - accuracy: 0.0299 - val_loss: 4.4790 - val_accuracy: 0.0339\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 4.2812 - accuracy: 0.0362 - val_loss: 4.3790 - val_accuracy: 0.0468\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 4.0625 - accuracy: 0.0493 - val_loss: 3.9946 - val_accuracy: 0.0516\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 3.8648 - accuracy: 0.0643 - val_loss: 3.7805 - val_accuracy: 0.0790\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 3.6924 - accuracy: 0.0846 - val_loss: 3.6042 - val_accuracy: 0.1129\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 3.5482 - accuracy: 0.0966 - val_loss: 3.4959 - val_accuracy: 0.1226\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 3.4175 - accuracy: 0.1090 - val_loss: 3.3628 - val_accuracy: 0.1419\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 3.3529 - accuracy: 0.1287 - val_loss: 3.2620 - val_accuracy: 0.1597\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 3.2808 - accuracy: 0.1355 - val_loss: 3.1612 - val_accuracy: 0.1548\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 3.2163 - accuracy: 0.1434 - val_loss: 3.1213 - val_accuracy: 0.1903\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 3.1687 - accuracy: 0.1640 - val_loss: 3.0643 - val_accuracy: 0.1903\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 3.1505 - accuracy: 0.1588 - val_loss: 3.0198 - val_accuracy: 0.1984\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 3.0154 - accuracy: 0.1910 - val_loss: 2.8403 - val_accuracy: 0.2210\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 2.8572 - accuracy: 0.2315 - val_loss: 2.7011 - val_accuracy: 0.2984\n",
      "current best accuracy 0.2983871102333069\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.7048 - accuracy: 0.0136 - val_loss: 4.1605 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 4.1399 - accuracy: 0.0086 - val_loss: 4.1309 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.1297 - accuracy: 0.0118 - val_loss: 4.1282 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 4.1284 - accuracy: 0.0129 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.1279 - accuracy: 0.0147 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 4.1278 - accuracy: 0.0161 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 4.1278 - accuracy: 0.0133 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 119ms/step - loss: 4.1277 - accuracy: 0.0118 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.1277 - accuracy: 0.0104 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 4.1277 - accuracy: 0.0151 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 10s 118ms/step - loss: 4.1276 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 26s 148ms/step - loss: 6.7019 - accuracy: 0.0122 - val_loss: 5.4278 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 5.2079 - accuracy: 0.0111 - val_loss: 5.0269 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.9071 - accuracy: 0.0136 - val_loss: 4.8005 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.7231 - accuracy: 0.0120 - val_loss: 4.6527 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.5990 - accuracy: 0.0108 - val_loss: 4.5486 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.5088 - accuracy: 0.0142 - val_loss: 4.4707 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.4400 - accuracy: 0.0115 - val_loss: 4.4099 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 26s 148ms/step - loss: 4.3856 - accuracy: 0.0140 - val_loss: 4.3613 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.3416 - accuracy: 0.0133 - val_loss: 4.3216 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 26s 148ms/step - loss: 4.3054 - accuracy: 0.0134 - val_loss: 4.2888 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 26s 148ms/step - loss: 4.2755 - accuracy: 0.0120 - val_loss: 4.2615 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 25s 145ms/step - loss: 4.2504 - accuracy: 0.0109 - val_loss: 4.2386 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.2295 - accuracy: 0.0104 - val_loss: 4.2195 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.2119 - accuracy: 0.0106 - val_loss: 4.2035 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.1972 - accuracy: 0.0113 - val_loss: 4.1901 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.1849 - accuracy: 0.0129 - val_loss: 4.1788 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.1747 - accuracy: 0.0102 - val_loss: 4.1695 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 26s 148ms/step - loss: 4.1661 - accuracy: 0.0108 - val_loss: 4.1617 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.1591 - accuracy: 0.0124 - val_loss: 4.1553 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 26s 148ms/step - loss: 4.1532 - accuracy: 0.0127 - val_loss: 4.1501 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 15s 163ms/step - loss: 4.6189 - accuracy: 0.0147 - val_loss: 4.1681 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 4.1473 - accuracy: 0.0125 - val_loss: 4.1357 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1328 - accuracy: 0.0133 - val_loss: 4.1300 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 4.1296 - accuracy: 0.0129 - val_loss: 4.1283 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 13s 152ms/step - loss: 4.1285 - accuracy: 0.0136 - val_loss: 4.1277 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1280 - accuracy: 0.0133 - val_loss: 4.1274 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1278 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1278 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1278 - accuracy: 0.0111 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 4.1277 - accuracy: 0.0154 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 4.1276 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 4.1277 - accuracy: 0.0165 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 4.1276 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 4.1276 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 4.1276 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 5.7868 - accuracy: 0.0127 - val_loss: 5.0022 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 25s 146ms/step - loss: 4.8513 - accuracy: 0.0097 - val_loss: 4.7274 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.6456 - accuracy: 0.0113 - val_loss: 4.5736 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.5213 - accuracy: 0.0136 - val_loss: 4.4731 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.4366 - accuracy: 0.0109 - val_loss: 4.4025 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 25s 146ms/step - loss: 4.3872 - accuracy: 0.0120 - val_loss: 4.3556 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.3323 - accuracy: 0.0106 - val_loss: 4.3115 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.2997 - accuracy: 0.0152 - val_loss: 4.2911 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 25s 145ms/step - loss: 4.2687 - accuracy: 0.0134 - val_loss: 4.2516 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 25s 144ms/step - loss: 4.2400 - accuracy: 0.0099 - val_loss: 4.2281 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 25s 145ms/step - loss: 4.2193 - accuracy: 0.0129 - val_loss: 4.2098 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.2028 - accuracy: 0.0122 - val_loss: 4.1949 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 25s 145ms/step - loss: 4.1893 - accuracy: 0.0118 - val_loss: 4.1828 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.1784 - accuracy: 0.0116 - val_loss: 4.1729 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.1694 - accuracy: 0.0136 - val_loss: 4.1648 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 26s 149ms/step - loss: 4.1620 - accuracy: 0.0125 - val_loss: 4.1581 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 25s 145ms/step - loss: 4.1559 - accuracy: 0.0127 - val_loss: 4.1527 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.1510 - accuracy: 0.0116 - val_loss: 4.1482 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.1469 - accuracy: 0.0142 - val_loss: 4.1445 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.1436 - accuracy: 0.0122 - val_loss: 4.1415 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 14s 152ms/step - loss: 4.4820 - accuracy: 0.0151 - val_loss: 4.1468 - val_accuracy: 0.0290\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 3.9682 - accuracy: 0.0652 - val_loss: 3.4198 - val_accuracy: 0.2065\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 2.9219 - accuracy: 0.2821 - val_loss: 2.2306 - val_accuracy: 0.4645\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 2.1120 - accuracy: 0.4860 - val_loss: 1.7236 - val_accuracy: 0.6129\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 1.7602 - accuracy: 0.5663 - val_loss: 1.5139 - val_accuracy: 0.6919\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 1.5345 - accuracy: 0.6312 - val_loss: 1.3973 - val_accuracy: 0.6887\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 1.3984 - accuracy: 0.6613 - val_loss: 1.3912 - val_accuracy: 0.7016\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 1.3059 - accuracy: 0.6778 - val_loss: 1.3030 - val_accuracy: 0.7048\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 1.2205 - accuracy: 0.7004 - val_loss: 1.1858 - val_accuracy: 0.7387\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 1.1336 - accuracy: 0.7323 - val_loss: 1.1748 - val_accuracy: 0.7484\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 1.1197 - accuracy: 0.7262 - val_loss: 1.1394 - val_accuracy: 0.7516\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 1.1116 - accuracy: 0.7405 - val_loss: 1.1965 - val_accuracy: 0.7226\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 1.0738 - accuracy: 0.7491 - val_loss: 1.1769 - val_accuracy: 0.7435\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 1.0095 - accuracy: 0.7753 - val_loss: 1.1946 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 1.0140 - accuracy: 0.7688 - val_loss: 1.1129 - val_accuracy: 0.7661\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.9753 - accuracy: 0.7817 - val_loss: 1.1299 - val_accuracy: 0.7661\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.9912 - accuracy: 0.7781 - val_loss: 1.1228 - val_accuracy: 0.7726\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 0.9287 - accuracy: 0.7878 - val_loss: 1.1389 - val_accuracy: 0.7758\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 13s 151ms/step - loss: 0.9257 - accuracy: 0.7946 - val_loss: 1.1920 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 13s 149ms/step - loss: 0.9113 - accuracy: 0.7982 - val_loss: 1.1402 - val_accuracy: 0.7742\n",
      "current best accuracy 0.7758064270019531\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 7.3642 - accuracy: 0.0104 - val_loss: 5.8174 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 5.5775 - accuracy: 0.0131 - val_loss: 5.3697 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 25s 146ms/step - loss: 5.2241 - accuracy: 0.0116 - val_loss: 5.0885 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 26s 147ms/step - loss: 4.9852 - accuracy: 0.0133 - val_loss: 4.8897 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 25s 146ms/step - loss: 4.8140 - accuracy: 0.0109 - val_loss: 4.7423 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.6841 - accuracy: 0.0136 - val_loss: 4.6283 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 25s 146ms/step - loss: 4.6058 - accuracy: 0.0156 - val_loss: 4.5639 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.4603 - accuracy: 0.0280 - val_loss: 4.5024 - val_accuracy: 0.0661\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 26s 146ms/step - loss: 4.1469 - accuracy: 0.1106 - val_loss: 3.8976 - val_accuracy: 0.1629\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 46s 264ms/step - loss: 3.4431 - accuracy: 0.2133 - val_loss: 3.1160 - val_accuracy: 0.3081\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 2.9013 - accuracy: 0.3090 - val_loss: 2.6497 - val_accuracy: 0.4097\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 30s 169ms/step - loss: 2.4878 - accuracy: 0.4194 - val_loss: 2.2947 - val_accuracy: 0.5306\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 2.2736 - accuracy: 0.4737 - val_loss: 2.1601 - val_accuracy: 0.5516\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 2.0987 - accuracy: 0.5138 - val_loss: 2.0925 - val_accuracy: 0.5242\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 1.9866 - accuracy: 0.5323 - val_loss: 1.9989 - val_accuracy: 0.5371\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 27s 153ms/step - loss: 1.9147 - accuracy: 0.5523 - val_loss: 1.8336 - val_accuracy: 0.6048\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 27s 152ms/step - loss: 1.8001 - accuracy: 0.5771 - val_loss: 1.7831 - val_accuracy: 0.6032\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 26s 150ms/step - loss: 1.7577 - accuracy: 0.5837 - val_loss: 1.7957 - val_accuracy: 0.6161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 26s 151ms/step - loss: 1.6759 - accuracy: 0.6079 - val_loss: 1.7584 - val_accuracy: 0.5968\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 26s 151ms/step - loss: 1.6481 - accuracy: 0.6065 - val_loss: 1.5825 - val_accuracy: 0.6500\n",
      "current best accuracy 0.6499999761581421\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.6728 - accuracy: 0.0219 - val_loss: 4.1445 - val_accuracy: 0.0194\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 3.8907 - accuracy: 0.0796 - val_loss: 3.3995 - val_accuracy: 0.1774\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 3.1383 - accuracy: 0.2215 - val_loss: 2.8230 - val_accuracy: 0.2839\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 2.7467 - accuracy: 0.3133 - val_loss: 2.4098 - val_accuracy: 0.4016\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 2.4583 - accuracy: 0.3778 - val_loss: 2.1519 - val_accuracy: 0.4903\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 2.2492 - accuracy: 0.4520 - val_loss: 1.9864 - val_accuracy: 0.5452\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 2.0837 - accuracy: 0.4946 - val_loss: 1.8224 - val_accuracy: 0.5694\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.8933 - accuracy: 0.5323 - val_loss: 1.7213 - val_accuracy: 0.6387\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.7601 - accuracy: 0.5771 - val_loss: 1.6144 - val_accuracy: 0.6435\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.7141 - accuracy: 0.5964 - val_loss: 1.5377 - val_accuracy: 0.6742\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.6167 - accuracy: 0.6068 - val_loss: 1.4677 - val_accuracy: 0.7048\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.5569 - accuracy: 0.6258 - val_loss: 1.5092 - val_accuracy: 0.7081\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.4993 - accuracy: 0.6423 - val_loss: 1.4069 - val_accuracy: 0.7081\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.4368 - accuracy: 0.6591 - val_loss: 1.3838 - val_accuracy: 0.7258\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.4207 - accuracy: 0.6688 - val_loss: 1.3438 - val_accuracy: 0.7435\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3800 - accuracy: 0.6695 - val_loss: 1.3188 - val_accuracy: 0.7435\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.3295 - accuracy: 0.6896 - val_loss: 1.3198 - val_accuracy: 0.7452\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.3456 - accuracy: 0.6738 - val_loss: 1.3276 - val_accuracy: 0.7355\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2840 - accuracy: 0.7100 - val_loss: 1.3009 - val_accuracy: 0.7452\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 1.2752 - accuracy: 0.7111 - val_loss: 1.3211 - val_accuracy: 0.7452\n",
      "current best accuracy 0.7451612949371338\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 22s 121ms/step - loss: 6.7029 - accuracy: 0.0185 - val_loss: 5.4518 - val_accuracy: 0.0210\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 5.0851 - accuracy: 0.0548 - val_loss: 4.9330 - val_accuracy: 0.0871\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 4.2968 - accuracy: 0.1427 - val_loss: 3.7753 - val_accuracy: 0.2645\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 3.6144 - accuracy: 0.2427 - val_loss: 3.2264 - val_accuracy: 0.3323\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 3.1748 - accuracy: 0.3186 - val_loss: 2.8709 - val_accuracy: 0.3984\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.9058 - accuracy: 0.3677 - val_loss: 2.7154 - val_accuracy: 0.4194\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.6591 - accuracy: 0.4133 - val_loss: 2.4379 - val_accuracy: 0.4742\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 22s 123ms/step - loss: 2.4655 - accuracy: 0.4487 - val_loss: 2.2924 - val_accuracy: 0.5177\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.2520 - accuracy: 0.4916 - val_loss: 2.1283 - val_accuracy: 0.5355\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.0600 - accuracy: 0.5341 - val_loss: 1.9481 - val_accuracy: 0.5548\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.9881 - accuracy: 0.5378 - val_loss: 1.9113 - val_accuracy: 0.5839\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.8792 - accuracy: 0.5514 - val_loss: 1.8043 - val_accuracy: 0.6016\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.8222 - accuracy: 0.5659 - val_loss: 1.7083 - val_accuracy: 0.6194\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.7446 - accuracy: 0.5817 - val_loss: 1.7728 - val_accuracy: 0.5871\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.6813 - accuracy: 0.6029 - val_loss: 1.6470 - val_accuracy: 0.6371\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.6087 - accuracy: 0.6163 - val_loss: 1.6275 - val_accuracy: 0.6113\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 1.5919 - accuracy: 0.6118 - val_loss: 1.7033 - val_accuracy: 0.5968\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.5630 - accuracy: 0.6194 - val_loss: 1.5562 - val_accuracy: 0.6226\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 1.5126 - accuracy: 0.6346 - val_loss: 1.5105 - val_accuracy: 0.6452\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 1.4842 - accuracy: 0.6392 - val_loss: 1.4818 - val_accuracy: 0.6419\n",
      "current best accuracy 0.6451612710952759\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 13s 136ms/step - loss: 4.6225 - accuracy: 0.0151 - val_loss: 4.1624 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 4.1421 - accuracy: 0.0100 - val_loss: 4.1325 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.1309 - accuracy: 0.0122 - val_loss: 4.1289 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 4.1289 - accuracy: 0.0129 - val_loss: 4.1279 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 4.1282 - accuracy: 0.0133 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 4.1280 - accuracy: 0.0133 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 12s 136ms/step - loss: 4.1279 - accuracy: 0.0151 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 4.1278 - accuracy: 0.0122 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.1278 - accuracy: 0.0143 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 4.1278 - accuracy: 0.0151 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.1276 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.1277 - accuracy: 0.0100 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 4.1278 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 12s 135ms/step - loss: 4.1277 - accuracy: 0.0115 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 12s 134ms/step - loss: 4.1276 - accuracy: 0.0151 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 24s 131ms/step - loss: 6.8313 - accuracy: 0.0113 - val_loss: 5.2978 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 5.1484 - accuracy: 0.0122 - val_loss: 5.0188 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.9312 - accuracy: 0.0109 - val_loss: 4.8428 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.7774 - accuracy: 0.0124 - val_loss: 4.7163 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 4.6678 - accuracy: 0.0115 - val_loss: 4.6214 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.5838 - accuracy: 0.0142 - val_loss: 4.5470 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.5167 - accuracy: 0.0133 - val_loss: 4.4867 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.4625 - accuracy: 0.0108 - val_loss: 4.4407 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 4.4179 - accuracy: 0.0129 - val_loss: 4.3959 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.3779 - accuracy: 0.0125 - val_loss: 4.3593 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 4.3440 - accuracy: 0.0133 - val_loss: 4.3278 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.3145 - accuracy: 0.0122 - val_loss: 4.3005 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.2890 - accuracy: 0.0152 - val_loss: 4.2767 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.2668 - accuracy: 0.0120 - val_loss: 4.2559 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 4.2473 - accuracy: 0.0131 - val_loss: 4.2377 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 4.2302 - accuracy: 0.0111 - val_loss: 4.2218 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 4.2154 - accuracy: 0.0124 - val_loss: 4.2079 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 23s 130ms/step - loss: 4.2024 - accuracy: 0.0131 - val_loss: 4.1958 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.1911 - accuracy: 0.0104 - val_loss: 4.1853 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 4.1813 - accuracy: 0.0106 - val_loss: 4.1762 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 4.5510 - accuracy: 0.0301 - val_loss: 3.8795 - val_accuracy: 0.0968\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 3.4536 - accuracy: 0.1681 - val_loss: 2.8095 - val_accuracy: 0.3097\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 2.5754 - accuracy: 0.3616 - val_loss: 2.3125 - val_accuracy: 0.4613\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 2.1469 - accuracy: 0.4706 - val_loss: 1.9177 - val_accuracy: 0.5500\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 131ms/step - loss: 1.8038 - accuracy: 0.5688 - val_loss: 1.6764 - val_accuracy: 0.6323\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.6254 - accuracy: 0.6158 - val_loss: 1.5380 - val_accuracy: 0.6629\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.4696 - accuracy: 0.6599 - val_loss: 1.5260 - val_accuracy: 0.6484\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.4020 - accuracy: 0.6875 - val_loss: 1.4982 - val_accuracy: 0.6823\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2854 - accuracy: 0.7154 - val_loss: 1.4370 - val_accuracy: 0.6968\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.1883 - accuracy: 0.7470 - val_loss: 1.3789 - val_accuracy: 0.7194\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.1656 - accuracy: 0.7452 - val_loss: 1.3873 - val_accuracy: 0.7177\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.1461 - accuracy: 0.7577 - val_loss: 1.4136 - val_accuracy: 0.7065\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 1.0973 - accuracy: 0.7627 - val_loss: 1.3265 - val_accuracy: 0.7194\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 12s 133ms/step - loss: 1.0314 - accuracy: 0.7871 - val_loss: 1.3186 - val_accuracy: 0.7403\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.0067 - accuracy: 0.7986 - val_loss: 1.2749 - val_accuracy: 0.7661\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 0.9627 - accuracy: 0.8097 - val_loss: 1.2434 - val_accuracy: 0.7565\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 0.9394 - accuracy: 0.8204 - val_loss: 1.2601 - val_accuracy: 0.7710\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 0.9353 - accuracy: 0.8297 - val_loss: 1.3165 - val_accuracy: 0.7323\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 0.9218 - accuracy: 0.8194 - val_loss: 1.2324 - val_accuracy: 0.7645\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 0.8600 - accuracy: 0.8430 - val_loss: 1.2547 - val_accuracy: 0.7661\n",
      "current best accuracy 0.7709677219390869\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 23s 127ms/step - loss: 7.4663 - accuracy: 0.0100 - val_loss: 5.6672 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 5.4310 - accuracy: 0.0211 - val_loss: 5.2774 - val_accuracy: 0.0581\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 4.4303 - accuracy: 0.2210 - val_loss: 4.0469 - val_accuracy: 0.2210\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 2.9519 - accuracy: 0.4690 - val_loss: 2.6963 - val_accuracy: 0.5226\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 2.3274 - accuracy: 0.5866 - val_loss: 2.3443 - val_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 2.0178 - accuracy: 0.6493 - val_loss: 2.1363 - val_accuracy: 0.6419\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.8219 - accuracy: 0.6733 - val_loss: 1.9708 - val_accuracy: 0.6435\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.6638 - accuracy: 0.7059 - val_loss: 1.8834 - val_accuracy: 0.6548\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.5078 - accuracy: 0.7310 - val_loss: 1.7561 - val_accuracy: 0.6887\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.4202 - accuracy: 0.7357 - val_loss: 1.7103 - val_accuracy: 0.6774\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.3438 - accuracy: 0.7536 - val_loss: 1.6011 - val_accuracy: 0.7145\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.2655 - accuracy: 0.7654 - val_loss: 1.5244 - val_accuracy: 0.7290\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.1871 - accuracy: 0.7828 - val_loss: 1.5023 - val_accuracy: 0.7161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.1426 - accuracy: 0.7832 - val_loss: 1.4152 - val_accuracy: 0.7306\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.0868 - accuracy: 0.8073 - val_loss: 1.4230 - val_accuracy: 0.7290\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.0407 - accuracy: 0.8004 - val_loss: 1.3492 - val_accuracy: 0.7403\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.0169 - accuracy: 0.8120 - val_loss: 1.2956 - val_accuracy: 0.7677\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.9881 - accuracy: 0.8118 - val_loss: 1.3547 - val_accuracy: 0.7242\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 0.9412 - accuracy: 0.8231 - val_loss: 1.3235 - val_accuracy: 0.7387\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.9252 - accuracy: 0.8265 - val_loss: 1.2941 - val_accuracy: 0.7435\n",
      "current best accuracy 0.7677419185638428\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 4.6502 - accuracy: 0.0384 - val_loss: 3.7444 - val_accuracy: 0.1355\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 3.1126 - accuracy: 0.2742 - val_loss: 2.5332 - val_accuracy: 0.4323\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 2.3831 - accuracy: 0.4290 - val_loss: 2.1206 - val_accuracy: 0.4968\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 2.0677 - accuracy: 0.5201 - val_loss: 1.9629 - val_accuracy: 0.5677\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 1.8228 - accuracy: 0.5975 - val_loss: 1.8756 - val_accuracy: 0.6032\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 1.6802 - accuracy: 0.6419 - val_loss: 1.7238 - val_accuracy: 0.6581\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 1.5244 - accuracy: 0.6799 - val_loss: 1.6382 - val_accuracy: 0.6710\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 1.3942 - accuracy: 0.7172 - val_loss: 1.5208 - val_accuracy: 0.7161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 1.2818 - accuracy: 0.7462 - val_loss: 1.4814 - val_accuracy: 0.7339\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 1.2325 - accuracy: 0.7613 - val_loss: 1.4527 - val_accuracy: 0.7210\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.1820 - accuracy: 0.7735 - val_loss: 1.4147 - val_accuracy: 0.7290\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 1.1620 - accuracy: 0.7867 - val_loss: 1.3667 - val_accuracy: 0.7629\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 1.0768 - accuracy: 0.8000 - val_loss: 1.3777 - val_accuracy: 0.7306\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 1.0452 - accuracy: 0.8229 - val_loss: 1.3716 - val_accuracy: 0.7242\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 1.0039 - accuracy: 0.8280 - val_loss: 1.3170 - val_accuracy: 0.7677\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.9730 - accuracy: 0.8462 - val_loss: 1.3448 - val_accuracy: 0.7548\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 0.9455 - accuracy: 0.8391 - val_loss: 1.3131 - val_accuracy: 0.7629\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 0.9285 - accuracy: 0.8538 - val_loss: 1.3874 - val_accuracy: 0.7581\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 0.9367 - accuracy: 0.8455 - val_loss: 1.2868 - val_accuracy: 0.7516\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 0.8850 - accuracy: 0.8538 - val_loss: 1.2356 - val_accuracy: 0.7823\n",
      "current best accuracy 0.7822580933570862\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 30s 168ms/step - loss: 6.2580 - accuracy: 0.0133 - val_loss: 5.3772 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 5.1774 - accuracy: 0.0102 - val_loss: 5.0086 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.8912 - accuracy: 0.0113 - val_loss: 4.7865 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 29s 166ms/step - loss: 4.7083 - accuracy: 0.0152 - val_loss: 4.6362 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.5804 - accuracy: 0.0102 - val_loss: 4.5277 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.4860 - accuracy: 0.0133 - val_loss: 4.4459 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.4142 - accuracy: 0.0108 - val_loss: 4.3832 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 29s 168ms/step - loss: 4.3575 - accuracy: 0.0149 - val_loss: 4.3324 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 29s 168ms/step - loss: 4.3123 - accuracy: 0.0088 - val_loss: 4.2922 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.2765 - accuracy: 0.0134 - val_loss: 4.2600 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 29s 166ms/step - loss: 4.2470 - accuracy: 0.0116 - val_loss: 4.2335 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 29s 168ms/step - loss: 4.2232 - accuracy: 0.0104 - val_loss: 4.2122 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.2040 - accuracy: 0.0129 - val_loss: 4.1949 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.1884 - accuracy: 0.0125 - val_loss: 4.1810 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 29s 168ms/step - loss: 4.1760 - accuracy: 0.0118 - val_loss: 4.1699 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.1660 - accuracy: 0.0133 - val_loss: 4.1610 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.1580 - accuracy: 0.0106 - val_loss: 4.1540 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.1517 - accuracy: 0.0127 - val_loss: 4.1484 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.1467 - accuracy: 0.0118 - val_loss: 4.1440 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 4.1429 - accuracy: 0.0129 - val_loss: 4.1406 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 15s 169ms/step - loss: 4.5974 - accuracy: 0.0133 - val_loss: 4.1583 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1418 - accuracy: 0.0118 - val_loss: 4.1329 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1313 - accuracy: 0.0122 - val_loss: 4.1293 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1289 - accuracy: 0.0133 - val_loss: 4.1279 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1282 - accuracy: 0.0151 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1280 - accuracy: 0.0143 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1278 - accuracy: 0.0133 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1278 - accuracy: 0.0140 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1277 - accuracy: 0.0151 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1277 - accuracy: 0.0079 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1276 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 29s 161ms/step - loss: 6.3896 - accuracy: 0.0267 - val_loss: 5.3310 - val_accuracy: 0.0823\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 4.4809 - accuracy: 0.2029 - val_loss: 4.1703 - val_accuracy: 0.1952\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 3.0310 - accuracy: 0.4419 - val_loss: 2.7624 - val_accuracy: 0.5452\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 2.3497 - accuracy: 0.5849 - val_loss: 2.2153 - val_accuracy: 0.6323\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 1.9293 - accuracy: 0.6670 - val_loss: 1.9069 - val_accuracy: 0.6871\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.6899 - accuracy: 0.7061 - val_loss: 1.7096 - val_accuracy: 0.7242\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 1.5233 - accuracy: 0.7348 - val_loss: 1.5650 - val_accuracy: 0.7145\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 1.3697 - accuracy: 0.7624 - val_loss: 1.5234 - val_accuracy: 0.7081\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.2534 - accuracy: 0.7837 - val_loss: 1.4220 - val_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 1.1653 - accuracy: 0.7900 - val_loss: 1.2965 - val_accuracy: 0.7694\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 1.0892 - accuracy: 0.8079 - val_loss: 1.3293 - val_accuracy: 0.7581\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.0282 - accuracy: 0.8188 - val_loss: 1.2467 - val_accuracy: 0.7694\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 1.0015 - accuracy: 0.8231 - val_loss: 1.2207 - val_accuracy: 0.7726\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 0.9511 - accuracy: 0.8283 - val_loss: 1.2304 - val_accuracy: 0.7710\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 0.9077 - accuracy: 0.8452 - val_loss: 1.1720 - val_accuracy: 0.7855\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 0.8522 - accuracy: 0.8495 - val_loss: 1.1197 - val_accuracy: 0.7871\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 0.8199 - accuracy: 0.8500 - val_loss: 1.1320 - val_accuracy: 0.7565\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 0.8143 - accuracy: 0.8541 - val_loss: 1.1160 - val_accuracy: 0.7790\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 0.7944 - accuracy: 0.8523 - val_loss: 1.0958 - val_accuracy: 0.7790\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 0.7789 - accuracy: 0.8523 - val_loss: 1.0840 - val_accuracy: 0.7790\n",
      "current best accuracy 0.7870967984199524\n",
      "updated best\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 15s 163ms/step - loss: 4.4329 - accuracy: 0.0412 - val_loss: 3.6559 - val_accuracy: 0.1290\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 3.1290 - accuracy: 0.2545 - val_loss: 2.6506 - val_accuracy: 0.3806\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 2.2681 - accuracy: 0.4624 - val_loss: 1.9334 - val_accuracy: 0.5742\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 14s 163ms/step - loss: 1.8119 - accuracy: 0.5871 - val_loss: 1.7275 - val_accuracy: 0.6194\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.5346 - accuracy: 0.6645 - val_loss: 1.5301 - val_accuracy: 0.6935\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 1.3629 - accuracy: 0.7043 - val_loss: 1.4347 - val_accuracy: 0.7097\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 1.2405 - accuracy: 0.7247 - val_loss: 1.3786 - val_accuracy: 0.7290\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 1.1999 - accuracy: 0.7520 - val_loss: 1.3795 - val_accuracy: 0.7452\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 1.1033 - accuracy: 0.7763 - val_loss: 1.3642 - val_accuracy: 0.7339\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 14s 163ms/step - loss: 1.0433 - accuracy: 0.7885 - val_loss: 1.3240 - val_accuracy: 0.7452\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 1.0249 - accuracy: 0.7957 - val_loss: 1.4182 - val_accuracy: 0.7210\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 0.9781 - accuracy: 0.8061 - val_loss: 1.2755 - val_accuracy: 0.7452\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 0.9254 - accuracy: 0.8194 - val_loss: 1.3273 - val_accuracy: 0.7484\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 0.9264 - accuracy: 0.8265 - val_loss: 1.3403 - val_accuracy: 0.7323\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 0.8861 - accuracy: 0.8405 - val_loss: 1.2697 - val_accuracy: 0.7726\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 0.8196 - accuracy: 0.8577 - val_loss: 1.3514 - val_accuracy: 0.7645\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 0.8469 - accuracy: 0.8498 - val_loss: 1.3227 - val_accuracy: 0.7565\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 0.7933 - accuracy: 0.8649 - val_loss: 1.2846 - val_accuracy: 0.7613\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 0.8154 - accuracy: 0.8556 - val_loss: 1.2573 - val_accuracy: 0.7694\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 0.7693 - accuracy: 0.8738 - val_loss: 1.3168 - val_accuracy: 0.7597\n",
      "current best accuracy 0.772580623626709\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 28s 155ms/step - loss: 6.4988 - accuracy: 0.0113 - val_loss: 5.4447 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 5.2055 - accuracy: 0.0147 - val_loss: 5.0107 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 4.8825 - accuracy: 0.0140 - val_loss: 4.7708 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.6902 - accuracy: 0.0118 - val_loss: 4.6170 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 4.5613 - accuracy: 0.0120 - val_loss: 4.5091 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.4682 - accuracy: 0.0120 - val_loss: 4.4290 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.3979 - accuracy: 0.0111 - val_loss: 4.3676 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.3434 - accuracy: 0.0113 - val_loss: 4.3194 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.3004 - accuracy: 0.0136 - val_loss: 4.2812 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.2661 - accuracy: 0.0127 - val_loss: 4.2506 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 4.2386 - accuracy: 0.0109 - val_loss: 4.2260 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 4.2164 - accuracy: 0.0125 - val_loss: 4.2062 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.1985 - accuracy: 0.0147 - val_loss: 4.1901 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 27s 152ms/step - loss: 4.1841 - accuracy: 0.0142 - val_loss: 4.1772 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.1725 - accuracy: 0.0133 - val_loss: 4.1668 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.1632 - accuracy: 0.0122 - val_loss: 4.1585 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 4.1557 - accuracy: 0.0143 - val_loss: 4.1518 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 4.1498 - accuracy: 0.0116 - val_loss: 4.1527 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 4.1465 - accuracy: 0.0113 - val_loss: 4.1425 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.1412 - accuracy: 0.0118 - val_loss: 4.1390 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.1, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 14s 154ms/step - loss: 4.6334 - accuracy: 0.0108 - val_loss: 4.1436 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 4.1339 - accuracy: 0.0100 - val_loss: 4.1291 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1288 - accuracy: 0.0143 - val_loss: 4.1277 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 4.1280 - accuracy: 0.0154 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1278 - accuracy: 0.0158 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 4.1276 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1276 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 14s 154ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 13s 153ms/step - loss: 4.1276 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 14s 154ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1277 - accuracy: 0.0104 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 4.1277 - accuracy: 0.0108 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 4.1277 - accuracy: 0.0072 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 6.8448 - accuracy: 0.0115 - val_loss: 5.4564 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 5.2557 - accuracy: 0.0106 - val_loss: 5.0871 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.9836 - accuracy: 0.0122 - val_loss: 4.8794 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.7977 - accuracy: 0.0115 - val_loss: 4.7231 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.6651 - accuracy: 0.0118 - val_loss: 4.6102 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.5719 - accuracy: 0.0136 - val_loss: 4.5309 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.4938 - accuracy: 0.0129 - val_loss: 4.4583 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 4.4320 - accuracy: 0.0122 - val_loss: 4.4075 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.3824 - accuracy: 0.0136 - val_loss: 4.3575 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.3381 - accuracy: 0.0134 - val_loss: 4.3184 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 4.3027 - accuracy: 0.0116 - val_loss: 4.2864 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.2736 - accuracy: 0.0147 - val_loss: 4.2599 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.2493 - accuracy: 0.0115 - val_loss: 4.2379 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.2291 - accuracy: 0.0100 - val_loss: 4.2195 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.2123 - accuracy: 0.0097 - val_loss: 4.2041 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.1981 - accuracy: 0.0115 - val_loss: 4.1912 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.1863 - accuracy: 0.0113 - val_loss: 4.1804 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.1764 - accuracy: 0.0124 - val_loss: 4.1714 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.1682 - accuracy: 0.0142 - val_loss: 4.1639 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 4.1613 - accuracy: 0.0111 - val_loss: 4.1576 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.6123 - accuracy: 0.0380 - val_loss: 3.6342 - val_accuracy: 0.1548\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 3.1704 - accuracy: 0.2416 - val_loss: 2.4240 - val_accuracy: 0.4516\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 2.3430 - accuracy: 0.4570 - val_loss: 1.9116 - val_accuracy: 0.6032\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.9146 - accuracy: 0.5821 - val_loss: 1.5910 - val_accuracy: 0.7129\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.6931 - accuracy: 0.6362 - val_loss: 1.5719 - val_accuracy: 0.7097\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.5107 - accuracy: 0.6846 - val_loss: 1.5035 - val_accuracy: 0.6952\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.4017 - accuracy: 0.7097 - val_loss: 1.3825 - val_accuracy: 0.7387\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3040 - accuracy: 0.7419 - val_loss: 1.3420 - val_accuracy: 0.7484\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.2396 - accuracy: 0.7502 - val_loss: 1.3246 - val_accuracy: 0.7452\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.1739 - accuracy: 0.7663 - val_loss: 1.2945 - val_accuracy: 0.7758\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.1563 - accuracy: 0.7824 - val_loss: 1.3147 - val_accuracy: 0.7661\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 1.0837 - accuracy: 0.7910 - val_loss: 1.2556 - val_accuracy: 0.7790\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.0737 - accuracy: 0.7964 - val_loss: 1.2179 - val_accuracy: 0.8081\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.0495 - accuracy: 0.8022 - val_loss: 1.2556 - val_accuracy: 0.7726\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 1.0203 - accuracy: 0.8082 - val_loss: 1.2328 - val_accuracy: 0.7839\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.0108 - accuracy: 0.8125 - val_loss: 1.2132 - val_accuracy: 0.7823\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 0.9728 - accuracy: 0.8226 - val_loss: 1.2640 - val_accuracy: 0.7839\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 0.9740 - accuracy: 0.8269 - val_loss: 1.1987 - val_accuracy: 0.7952\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 0.9682 - accuracy: 0.8283 - val_loss: 1.1925 - val_accuracy: 0.8016\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 0.9316 - accuracy: 0.8416 - val_loss: 1.2030 - val_accuracy: 0.7790\n",
      "current best accuracy 0.8080645203590393\n",
      "updated best\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 22s 120ms/step - loss: 6.7026 - accuracy: 0.0131 - val_loss: 5.3323 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 5.1645 - accuracy: 0.0115 - val_loss: 5.0208 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 4.9182 - accuracy: 0.0140 - val_loss: 4.8256 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 4.7551 - accuracy: 0.0115 - val_loss: 4.6894 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 4.6377 - accuracy: 0.0111 - val_loss: 4.5885 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 4.5490 - accuracy: 0.0100 - val_loss: 4.5107 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 4.4797 - accuracy: 0.0106 - val_loss: 4.4490 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 4.4240 - accuracy: 0.0142 - val_loss: 4.3990 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 4.3858 - accuracy: 0.0147 - val_loss: 4.3790 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 4.0915 - accuracy: 0.0780 - val_loss: 3.7095 - val_accuracy: 0.1565\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.9328 - accuracy: 0.2944 - val_loss: 2.5119 - val_accuracy: 0.4194\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.3018 - accuracy: 0.4559 - val_loss: 2.1008 - val_accuracy: 0.5532\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.9731 - accuracy: 0.5308 - val_loss: 1.8294 - val_accuracy: 0.6177\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.7455 - accuracy: 0.5952 - val_loss: 1.6000 - val_accuracy: 0.6919\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 1.6022 - accuracy: 0.6360 - val_loss: 1.4834 - val_accuracy: 0.7290\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 21s 119ms/step - loss: 1.4778 - accuracy: 0.6652 - val_loss: 1.4276 - val_accuracy: 0.7097\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.4219 - accuracy: 0.6785 - val_loss: 1.4020 - val_accuracy: 0.7274\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.3209 - accuracy: 0.7032 - val_loss: 1.3626 - val_accuracy: 0.7290\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.2730 - accuracy: 0.7156 - val_loss: 1.3559 - val_accuracy: 0.7323\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.2358 - accuracy: 0.7213 - val_loss: 1.2645 - val_accuracy: 0.7565\n",
      "current best accuracy 0.7564516067504883\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.6222 - accuracy: 0.0168 - val_loss: 4.2046 - val_accuracy: 0.0339\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 4.1680 - accuracy: 0.0140 - val_loss: 4.1437 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1378 - accuracy: 0.0158 - val_loss: 4.1329 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1316 - accuracy: 0.0147 - val_loss: 4.1296 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 4.1296 - accuracy: 0.0161 - val_loss: 4.1284 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1286 - accuracy: 0.0158 - val_loss: 4.1278 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1282 - accuracy: 0.0140 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 11s 125ms/step - loss: 4.1280 - accuracy: 0.0111 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1278 - accuracy: 0.0151 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1277 - accuracy: 0.0165 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1278 - accuracy: 0.0125 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1278 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1277 - accuracy: 0.0104 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1278 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.03387096896767616\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 22s 120ms/step - loss: 6.8933 - accuracy: 0.0127 - val_loss: 5.6006 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 5.3735 - accuracy: 0.0147 - val_loss: 5.1869 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 5.0561 - accuracy: 0.0134 - val_loss: 4.9409 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 4.8548 - accuracy: 0.0115 - val_loss: 4.7753 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 4.7229 - accuracy: 0.0161 - val_loss: 4.6831 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 4.3843 - accuracy: 0.0724 - val_loss: 4.0317 - val_accuracy: 0.1548\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 3.2146 - accuracy: 0.2891 - val_loss: 2.6974 - val_accuracy: 0.4548\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 2.5470 - accuracy: 0.4407 - val_loss: 2.2656 - val_accuracy: 0.5984\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.2591 - accuracy: 0.5007 - val_loss: 2.0399 - val_accuracy: 0.5984\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 2.0242 - accuracy: 0.5487 - val_loss: 1.8935 - val_accuracy: 0.6161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.8938 - accuracy: 0.5686 - val_loss: 1.7184 - val_accuracy: 0.6597\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.7870 - accuracy: 0.5909 - val_loss: 1.6410 - val_accuracy: 0.6710\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.7025 - accuracy: 0.6066 - val_loss: 1.5946 - val_accuracy: 0.6871\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.6169 - accuracy: 0.6247 - val_loss: 1.5613 - val_accuracy: 0.6823\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.5573 - accuracy: 0.6401 - val_loss: 1.4967 - val_accuracy: 0.6887\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.5163 - accuracy: 0.6496 - val_loss: 1.4363 - val_accuracy: 0.6968\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.4657 - accuracy: 0.6527 - val_loss: 1.4143 - val_accuracy: 0.6871\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.4188 - accuracy: 0.6690 - val_loss: 1.4510 - val_accuracy: 0.7097\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.3757 - accuracy: 0.6810 - val_loss: 1.3860 - val_accuracy: 0.7065\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 1.3564 - accuracy: 0.6855 - val_loss: 1.4417 - val_accuracy: 0.6823\n",
      "current best accuracy 0.7096773982048035\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.6905 - accuracy: 0.0140 - val_loss: 4.1554 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1385 - accuracy: 0.0143 - val_loss: 4.1309 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1298 - accuracy: 0.0125 - val_loss: 4.1282 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1285 - accuracy: 0.0147 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1279 - accuracy: 0.0143 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1277 - accuracy: 0.0108 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1277 - accuracy: 0.0154 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0151 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1277 - accuracy: 0.0154 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0108 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 11s 121ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 11s 120ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1276 - accuracy: 0.0158 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 28s 157ms/step - loss: 6.4381 - accuracy: 0.0118 - val_loss: 5.3898 - val_accuracy: 0.0113\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 5.1620 - accuracy: 0.0168 - val_loss: 4.9860 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 4.7999 - accuracy: 0.0249 - val_loss: 4.7546 - val_accuracy: 0.0274\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.5658 - accuracy: 0.0357 - val_loss: 4.5992 - val_accuracy: 0.0242\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 4.3180 - accuracy: 0.0577 - val_loss: 4.1171 - val_accuracy: 0.0742\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 3.8639 - accuracy: 0.1145 - val_loss: 3.5806 - val_accuracy: 0.2065\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 3.4472 - accuracy: 0.1939 - val_loss: 3.0776 - val_accuracy: 0.2935\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 3.0833 - accuracy: 0.2547 - val_loss: 2.7842 - val_accuracy: 0.4032\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 2.8336 - accuracy: 0.3125 - val_loss: 2.6140 - val_accuracy: 0.4194\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 2.5608 - accuracy: 0.3858 - val_loss: 2.1352 - val_accuracy: 0.5419\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 2.3078 - accuracy: 0.4470 - val_loss: 1.9865 - val_accuracy: 0.5742\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 27s 154ms/step - loss: 2.1219 - accuracy: 0.4878 - val_loss: 1.9062 - val_accuracy: 0.5758\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 1.9864 - accuracy: 0.5215 - val_loss: 1.7426 - val_accuracy: 0.6403\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 1.8739 - accuracy: 0.5500 - val_loss: 1.6707 - val_accuracy: 0.6548\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 1.7849 - accuracy: 0.5706 - val_loss: 1.5866 - val_accuracy: 0.6726\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 1.7593 - accuracy: 0.5692 - val_loss: 1.6025 - val_accuracy: 0.6710\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 1.6870 - accuracy: 0.5977 - val_loss: 1.4740 - val_accuracy: 0.6871\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 1.6371 - accuracy: 0.6066 - val_loss: 1.5603 - val_accuracy: 0.6839\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 27s 155ms/step - loss: 1.6078 - accuracy: 0.6203 - val_loss: 1.4239 - val_accuracy: 0.7016\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 27s 156ms/step - loss: 1.5878 - accuracy: 0.6174 - val_loss: 1.4076 - val_accuracy: 0.7210\n",
      "current best accuracy 0.7209677696228027\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 15s 159ms/step - loss: 4.5647 - accuracy: 0.0108 - val_loss: 4.1444 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1351 - accuracy: 0.0118 - val_loss: 4.1303 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1296 - accuracy: 0.0111 - val_loss: 4.1282 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1284 - accuracy: 0.0151 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1279 - accuracy: 0.0111 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1278 - accuracy: 0.0108 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1276 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 4.1276 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 5.9731 - accuracy: 0.0147 - val_loss: 5.1739 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 5.0026 - accuracy: 0.0122 - val_loss: 4.8584 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 4.7589 - accuracy: 0.0118 - val_loss: 4.6716 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 4.6049 - accuracy: 0.0142 - val_loss: 4.5443 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.4981 - accuracy: 0.0093 - val_loss: 4.4542 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.4205 - accuracy: 0.0131 - val_loss: 4.3874 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.3611 - accuracy: 0.0124 - val_loss: 4.3354 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 29s 165ms/step - loss: 4.3153 - accuracy: 0.0106 - val_loss: 4.2951 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.2793 - accuracy: 0.0106 - val_loss: 4.2632 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.2506 - accuracy: 0.0134 - val_loss: 4.2376 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.2277 - accuracy: 0.0118 - val_loss: 4.2171 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.2093 - accuracy: 0.0156 - val_loss: 4.2006 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 29s 165ms/step - loss: 4.1943 - accuracy: 0.0129 - val_loss: 4.1878 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.1651 - accuracy: 0.0177 - val_loss: 4.1881 - val_accuracy: 0.0210\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.0565 - accuracy: 0.0330 - val_loss: 3.9380 - val_accuracy: 0.0548\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 3.9081 - accuracy: 0.0486 - val_loss: 3.7886 - val_accuracy: 0.0548\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 3.7639 - accuracy: 0.0719 - val_loss: 3.7006 - val_accuracy: 0.0968\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 28s 163ms/step - loss: 3.5881 - accuracy: 0.1007 - val_loss: 3.3704 - val_accuracy: 0.1435\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 3.3666 - accuracy: 0.1384 - val_loss: 3.0958 - val_accuracy: 0.2161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 3.1505 - accuracy: 0.1814 - val_loss: 2.7267 - val_accuracy: 0.2726\n",
      "current best accuracy 0.27258065342903137\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 15s 164ms/step - loss: 4.5871 - accuracy: 0.0115 - val_loss: 4.1799 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1516 - accuracy: 0.0086 - val_loss: 4.1365 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1332 - accuracy: 0.0118 - val_loss: 4.1301 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 4.1296 - accuracy: 0.0125 - val_loss: 4.1284 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1286 - accuracy: 0.0154 - val_loss: 4.1278 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1281 - accuracy: 0.0154 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1279 - accuracy: 0.0125 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 14s 165ms/step - loss: 4.1278 - accuracy: 0.0125 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 14s 164ms/step - loss: 4.1277 - accuracy: 0.0115 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 14s 164ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 14s 165ms/step - loss: 4.1277 - accuracy: 0.0154 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 14s 164ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 14s 163ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 14s 164ms/step - loss: 4.1277 - accuracy: 0.0154 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 14s 163ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 14s 164ms/step - loss: 4.1277 - accuracy: 0.0151 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1277 - accuracy: 0.0151 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 4.1277 - accuracy: 0.0115 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 29s 161ms/step - loss: 6.9055 - accuracy: 0.0129 - val_loss: 5.7251 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 5.4639 - accuracy: 0.0111 - val_loss: 5.2423 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 5.0875 - accuracy: 0.0127 - val_loss: 4.9511 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 4.8543 - accuracy: 0.0086 - val_loss: 4.7584 - val_accuracy: 0.0145\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.6860 - accuracy: 0.0093 - val_loss: 4.6182 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 4.5647 - accuracy: 0.0124 - val_loss: 4.5136 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 4.4721 - accuracy: 0.0143 - val_loss: 4.4322 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.4187 - accuracy: 0.0116 - val_loss: 4.3805 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.3504 - accuracy: 0.0145 - val_loss: 4.3229 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 4.3026 - accuracy: 0.0138 - val_loss: 4.2819 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.2659 - accuracy: 0.0108 - val_loss: 4.2498 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 4.2375 - accuracy: 0.0109 - val_loss: 4.2246 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.2151 - accuracy: 0.0143 - val_loss: 4.2047 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.1972 - accuracy: 0.0091 - val_loss: 4.1890 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 4.1832 - accuracy: 0.0115 - val_loss: 4.1764 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 4.1738 - accuracy: 0.0143 - val_loss: 4.1675 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.1636 - accuracy: 0.0109 - val_loss: 4.1590 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.1563 - accuracy: 0.0138 - val_loss: 4.1526 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 4.1506 - accuracy: 0.0131 - val_loss: 4.1476 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 28s 158ms/step - loss: 4.1462 - accuracy: 0.0125 - val_loss: 4.1436 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 5, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 20s 210ms/step - loss: 4.6583 - accuracy: 0.0143 - val_loss: 4.1501 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 4.1365 - accuracy: 0.0115 - val_loss: 4.1300 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 4.1295 - accuracy: 0.0129 - val_loss: 4.1282 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 4.1282 - accuracy: 0.0125 - val_loss: 4.1274 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 4.1279 - accuracy: 0.0143 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 18s 208ms/step - loss: 4.1277 - accuracy: 0.0108 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 18s 207ms/step - loss: 4.1277 - accuracy: 0.0086 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 19s 218ms/step - loss: 4.1276 - accuracy: 0.0140 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 24s 275ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 28s 318ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 27s 303ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 27s 306ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 28s 314ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 27s 302ms/step - loss: 4.1276 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 26s 293ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 26s 295ms/step - loss: 4.1276 - accuracy: 0.0151 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 26s 291ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 26s 294ms/step - loss: 4.1277 - accuracy: 0.0093 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 26s 294ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 26s 291ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 34s 189ms/step - loss: 6.3373 - accuracy: 0.0127 - val_loss: 5.3777 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 5.1430 - accuracy: 0.0106 - val_loss: 4.9464 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 33s 188ms/step - loss: 4.8147 - accuracy: 0.0129 - val_loss: 4.7004 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.6193 - accuracy: 0.0124 - val_loss: 4.5464 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 33s 188ms/step - loss: 4.4924 - accuracy: 0.0125 - val_loss: 4.4426 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.4048 - accuracy: 0.0111 - val_loss: 4.3692 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 33s 188ms/step - loss: 4.3419 - accuracy: 0.0115 - val_loss: 4.3155 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.2952 - accuracy: 0.0099 - val_loss: 4.2752 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.2599 - accuracy: 0.0106 - val_loss: 4.2443 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.2326 - accuracy: 0.0111 - val_loss: 4.2204 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.2114 - accuracy: 0.0122 - val_loss: 4.2017 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.1947 - accuracy: 0.0131 - val_loss: 4.1870 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 33s 190ms/step - loss: 4.1815 - accuracy: 0.0118 - val_loss: 4.1753 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 4.1718 - accuracy: 0.0136 - val_loss: 4.1677 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 33s 190ms/step - loss: 4.1115 - accuracy: 0.0237 - val_loss: 4.1587 - val_accuracy: 0.0419\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 3.9139 - accuracy: 0.0484 - val_loss: 3.7434 - val_accuracy: 0.0629\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 3.6205 - accuracy: 0.0855 - val_loss: 3.3957 - val_accuracy: 0.1468\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 33s 188ms/step - loss: 3.3321 - accuracy: 0.1337 - val_loss: 3.0278 - val_accuracy: 0.2194\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 3.0891 - accuracy: 0.1763 - val_loss: 2.8722 - val_accuracy: 0.2774\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 33s 189ms/step - loss: 2.9989 - accuracy: 0.2029 - val_loss: 2.7179 - val_accuracy: 0.2984\n",
      "current best accuracy 0.2983871102333069\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 17s 186ms/step - loss: 4.5745 - accuracy: 0.0423 - val_loss: 3.5686 - val_accuracy: 0.1484\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 16s 184ms/step - loss: 3.2260 - accuracy: 0.2226 - val_loss: 2.4819 - val_accuracy: 0.4210\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 16s 184ms/step - loss: 2.5140 - accuracy: 0.3620 - val_loss: 2.0680 - val_accuracy: 0.4919\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 2.1656 - accuracy: 0.4627 - val_loss: 1.7993 - val_accuracy: 0.6032\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 16s 184ms/step - loss: 1.9404 - accuracy: 0.5312 - val_loss: 1.6818 - val_accuracy: 0.6226\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 16s 184ms/step - loss: 1.7196 - accuracy: 0.5903 - val_loss: 1.5682 - val_accuracy: 0.6548\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 16s 184ms/step - loss: 1.5740 - accuracy: 0.6237 - val_loss: 1.4457 - val_accuracy: 0.6774\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.4852 - accuracy: 0.6717 - val_loss: 1.3564 - val_accuracy: 0.7226\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 16s 184ms/step - loss: 1.3598 - accuracy: 0.6928 - val_loss: 1.3231 - val_accuracy: 0.7274\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.3225 - accuracy: 0.6975 - val_loss: 1.3268 - val_accuracy: 0.7274\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.2110 - accuracy: 0.7254 - val_loss: 1.2946 - val_accuracy: 0.7226\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.1949 - accuracy: 0.7344 - val_loss: 1.2901 - val_accuracy: 0.7419\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.1769 - accuracy: 0.7556 - val_loss: 1.2360 - val_accuracy: 0.7548\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.1061 - accuracy: 0.7785 - val_loss: 1.2120 - val_accuracy: 0.7742\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.0746 - accuracy: 0.7720 - val_loss: 1.1685 - val_accuracy: 0.7694\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 1.0414 - accuracy: 0.7918 - val_loss: 1.2844 - val_accuracy: 0.7468\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.0293 - accuracy: 0.7806 - val_loss: 1.1767 - val_accuracy: 0.7758\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.0269 - accuracy: 0.7961 - val_loss: 1.1981 - val_accuracy: 0.7710\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 0.9981 - accuracy: 0.8039 - val_loss: 1.1448 - val_accuracy: 0.7823\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 16s 185ms/step - loss: 0.9736 - accuracy: 0.8122 - val_loss: 1.1256 - val_accuracy: 0.8032\n",
      "current best accuracy 0.8032258152961731\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 31s 174ms/step - loss: 6.4373 - accuracy: 0.0151 - val_loss: 5.2529 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 31s 174ms/step - loss: 5.1021 - accuracy: 0.0142 - val_loss: 4.9721 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 30s 173ms/step - loss: 4.8925 - accuracy: 0.0149 - val_loss: 4.8125 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 4.4738 - accuracy: 0.0930 - val_loss: 4.4765 - val_accuracy: 0.1113\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 3.1772 - accuracy: 0.3446 - val_loss: 2.5479 - val_accuracy: 0.5081\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 2.3238 - accuracy: 0.5276 - val_loss: 2.0436 - val_accuracy: 0.6000\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 30s 173ms/step - loss: 1.9273 - accuracy: 0.6007 - val_loss: 1.8617 - val_accuracy: 0.6468\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 30s 173ms/step - loss: 1.7269 - accuracy: 0.6527 - val_loss: 1.6907 - val_accuracy: 0.6823\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 31s 175ms/step - loss: 1.5473 - accuracy: 0.7013 - val_loss: 1.5929 - val_accuracy: 0.7032\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 31s 175ms/step - loss: 1.4020 - accuracy: 0.7188 - val_loss: 1.4969 - val_accuracy: 0.7226\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 1.3022 - accuracy: 0.7439 - val_loss: 1.4485 - val_accuracy: 0.7194\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 1.2500 - accuracy: 0.7523 - val_loss: 1.4041 - val_accuracy: 0.7403\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 31s 175ms/step - loss: 1.1384 - accuracy: 0.7769 - val_loss: 1.3945 - val_accuracy: 0.7355\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 31s 174ms/step - loss: 1.1166 - accuracy: 0.7832 - val_loss: 1.3089 - val_accuracy: 0.7387\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 1.0851 - accuracy: 0.7835 - val_loss: 1.3114 - val_accuracy: 0.7403\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 30s 173ms/step - loss: 1.0118 - accuracy: 0.8018 - val_loss: 1.3332 - val_accuracy: 0.7435\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 1.0031 - accuracy: 0.8068 - val_loss: 1.2968 - val_accuracy: 0.7387\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 31s 174ms/step - loss: 0.9647 - accuracy: 0.8142 - val_loss: 1.2745 - val_accuracy: 0.7435\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 31s 175ms/step - loss: 0.9522 - accuracy: 0.8174 - val_loss: 1.2744 - val_accuracy: 0.7419\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 30s 174ms/step - loss: 0.9219 - accuracy: 0.8278 - val_loss: 1.2637 - val_accuracy: 0.7419\n",
      "current best accuracy 0.7435483932495117\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 16s 171ms/step - loss: 4.4365 - accuracy: 0.0455 - val_loss: 3.4795 - val_accuracy: 0.1694\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 3.1026 - accuracy: 0.2606 - val_loss: 2.3882 - val_accuracy: 0.4823\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 2.3190 - accuracy: 0.4609 - val_loss: 1.9013 - val_accuracy: 0.5968\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 15s 170ms/step - loss: 1.8918 - accuracy: 0.5785 - val_loss: 1.6328 - val_accuracy: 0.6742\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 15s 172ms/step - loss: 1.6570 - accuracy: 0.6301 - val_loss: 1.5324 - val_accuracy: 0.7129\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 15s 170ms/step - loss: 1.5458 - accuracy: 0.6720 - val_loss: 1.4893 - val_accuracy: 0.7113\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 15s 170ms/step - loss: 1.4058 - accuracy: 0.7022 - val_loss: 1.4735 - val_accuracy: 0.7210\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 1.3282 - accuracy: 0.7208 - val_loss: 1.4104 - val_accuracy: 0.7452\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 1.2547 - accuracy: 0.7373 - val_loss: 1.3173 - val_accuracy: 0.7532\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 1.2104 - accuracy: 0.7563 - val_loss: 1.2723 - val_accuracy: 0.7694\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 15s 170ms/step - loss: 1.1483 - accuracy: 0.7703 - val_loss: 1.3166 - val_accuracy: 0.7581\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 15s 170ms/step - loss: 1.1057 - accuracy: 0.7875 - val_loss: 1.2868 - val_accuracy: 0.7452\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 1.1009 - accuracy: 0.7821 - val_loss: 1.2545 - val_accuracy: 0.7694\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 1.0337 - accuracy: 0.8072 - val_loss: 1.3205 - val_accuracy: 0.7581\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 15s 170ms/step - loss: 1.0203 - accuracy: 0.8029 - val_loss: 1.3279 - val_accuracy: 0.7274\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 1.0123 - accuracy: 0.8072 - val_loss: 1.2350 - val_accuracy: 0.7855\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 0.9911 - accuracy: 0.8111 - val_loss: 1.1806 - val_accuracy: 0.7823\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 0.9912 - accuracy: 0.8108 - val_loss: 1.2042 - val_accuracy: 0.7790\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 15s 170ms/step - loss: 0.9526 - accuracy: 0.8215 - val_loss: 1.1572 - val_accuracy: 0.7726\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 15s 171ms/step - loss: 0.9328 - accuracy: 0.8315 - val_loss: 1.1677 - val_accuracy: 0.7806\n",
      "current best accuracy 0.7854838967323303\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 29s 162ms/step - loss: 6.8239 - accuracy: 0.0138 - val_loss: 5.5394 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 5.2984 - accuracy: 0.0127 - val_loss: 5.1030 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 4.9745 - accuracy: 0.0113 - val_loss: 4.8636 - val_accuracy: 0.0145\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 4.7250 - accuracy: 0.0385 - val_loss: 4.7511 - val_accuracy: 0.1710\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 3.4899 - accuracy: 0.2658 - val_loss: 2.8655 - val_accuracy: 0.4290\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 2.4301 - accuracy: 0.5099 - val_loss: 2.2523 - val_accuracy: 0.5661\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 2.0051 - accuracy: 0.5930 - val_loss: 1.9299 - val_accuracy: 0.6274\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 1.7550 - accuracy: 0.6516 - val_loss: 1.7534 - val_accuracy: 0.6694\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 1.6041 - accuracy: 0.6812 - val_loss: 1.7122 - val_accuracy: 0.6694\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 1.4644 - accuracy: 0.7100 - val_loss: 1.6091 - val_accuracy: 0.6774\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 1.3769 - accuracy: 0.7292 - val_loss: 1.5396 - val_accuracy: 0.6984\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 1.2931 - accuracy: 0.7443 - val_loss: 1.5023 - val_accuracy: 0.6968\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 1.2379 - accuracy: 0.7495 - val_loss: 1.4425 - val_accuracy: 0.7177\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.1771 - accuracy: 0.7695 - val_loss: 1.4118 - val_accuracy: 0.7226\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.1401 - accuracy: 0.7767 - val_loss: 1.3592 - val_accuracy: 0.7145\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.0900 - accuracy: 0.7849 - val_loss: 1.3619 - val_accuracy: 0.7242\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 1.0779 - accuracy: 0.7882 - val_loss: 1.3182 - val_accuracy: 0.7226\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.0618 - accuracy: 0.7801 - val_loss: 1.2840 - val_accuracy: 0.7323\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.0318 - accuracy: 0.7941 - val_loss: 1.3111 - val_accuracy: 0.7355\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 28s 161ms/step - loss: 1.0034 - accuracy: 0.8009 - val_loss: 1.3207 - val_accuracy: 0.7371\n",
      "current best accuracy 0.7370967864990234\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 3, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 15s 159ms/step - loss: 4.6907 - accuracy: 0.0251 - val_loss: 4.0292 - val_accuracy: 0.0419\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 3.7514 - accuracy: 0.0978 - val_loss: 3.1251 - val_accuracy: 0.2355\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 3.1126 - accuracy: 0.2201 - val_loss: 2.5568 - val_accuracy: 0.3710\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 2.7342 - accuracy: 0.2857 - val_loss: 2.3487 - val_accuracy: 0.4500\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 2.5085 - accuracy: 0.3448 - val_loss: 2.1208 - val_accuracy: 0.4984\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 2.3639 - accuracy: 0.3875 - val_loss: 2.0892 - val_accuracy: 0.5081\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 2.2865 - accuracy: 0.4043 - val_loss: 2.0768 - val_accuracy: 0.4855\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 2.1976 - accuracy: 0.4344 - val_loss: 1.8873 - val_accuracy: 0.5532\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 2.1186 - accuracy: 0.4470 - val_loss: 1.7984 - val_accuracy: 0.6048\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.9966 - accuracy: 0.4971 - val_loss: 1.7801 - val_accuracy: 0.6081\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.9068 - accuracy: 0.5118 - val_loss: 1.7784 - val_accuracy: 0.5823\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.9307 - accuracy: 0.5161 - val_loss: 1.7026 - val_accuracy: 0.6113\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.8498 - accuracy: 0.5362 - val_loss: 1.6543 - val_accuracy: 0.6145\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.7953 - accuracy: 0.5444 - val_loss: 1.6167 - val_accuracy: 0.6435\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.7524 - accuracy: 0.5563 - val_loss: 1.6105 - val_accuracy: 0.6226\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.7386 - accuracy: 0.5681 - val_loss: 1.6554 - val_accuracy: 0.6242\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.7012 - accuracy: 0.5853 - val_loss: 1.5753 - val_accuracy: 0.6726\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.6857 - accuracy: 0.5746 - val_loss: 1.6010 - val_accuracy: 0.6661\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.6903 - accuracy: 0.5803 - val_loss: 1.5350 - val_accuracy: 0.6435\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.6311 - accuracy: 0.5871 - val_loss: 1.5061 - val_accuracy: 0.6710\n",
      "current best accuracy 0.6725806593894958\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 39s 217ms/step - loss: 6.6268 - accuracy: 0.0140 - val_loss: 5.5926 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 38s 217ms/step - loss: 5.3891 - accuracy: 0.0143 - val_loss: 5.2142 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 38s 218ms/step - loss: 5.0855 - accuracy: 0.0116 - val_loss: 4.9691 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 38s 217ms/step - loss: 4.8795 - accuracy: 0.0116 - val_loss: 4.7962 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 38s 217ms/step - loss: 4.7307 - accuracy: 0.0113 - val_loss: 4.6680 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 38s 217ms/step - loss: 4.6166 - accuracy: 0.0090 - val_loss: 4.5671 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 38s 216ms/step - loss: 4.5265 - accuracy: 0.0154 - val_loss: 4.4870 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 38s 218ms/step - loss: 4.4606 - accuracy: 0.0124 - val_loss: 4.4284 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 38s 217ms/step - loss: 4.3991 - accuracy: 0.0136 - val_loss: 4.3712 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 38s 216ms/step - loss: 4.3493 - accuracy: 0.0129 - val_loss: 4.3282 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 38s 218ms/step - loss: 4.3089 - accuracy: 0.0102 - val_loss: 4.2900 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 38s 218ms/step - loss: 4.2760 - accuracy: 0.0152 - val_loss: 4.2655 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 40s 227ms/step - loss: 4.2402 - accuracy: 0.0224 - val_loss: 4.2502 - val_accuracy: 0.0452\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 40s 230ms/step - loss: 4.1066 - accuracy: 0.0491 - val_loss: 4.1370 - val_accuracy: 0.0565\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 39s 221ms/step - loss: 3.8988 - accuracy: 0.0674 - val_loss: 3.6724 - val_accuracy: 0.1258\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 39s 221ms/step - loss: 3.3928 - accuracy: 0.1588 - val_loss: 2.7904 - val_accuracy: 0.3194\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 38s 220ms/step - loss: 2.8512 - accuracy: 0.2703 - val_loss: 2.4068 - val_accuracy: 0.4065\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 40s 227ms/step - loss: 2.5733 - accuracy: 0.3254 - val_loss: 2.2014 - val_accuracy: 0.4903\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 40s 227ms/step - loss: 2.4513 - accuracy: 0.3468 - val_loss: 1.9963 - val_accuracy: 0.5226\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 39s 224ms/step - loss: 2.3441 - accuracy: 0.3855 - val_loss: 1.9605 - val_accuracy: 0.5306\n",
      "current best accuracy 0.5306451320648193\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 21s 229ms/step - loss: 4.5726 - accuracy: 0.0104 - val_loss: 4.1446 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 20s 223ms/step - loss: 4.1343 - accuracy: 0.0111 - val_loss: 4.1291 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 19s 215ms/step - loss: 4.1286 - accuracy: 0.0125 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 19s 213ms/step - loss: 4.1279 - accuracy: 0.0140 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 19s 214ms/step - loss: 4.1278 - accuracy: 0.0165 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 4.1277 - accuracy: 0.0154 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 19s 213ms/step - loss: 4.1276 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 19s 213ms/step - loss: 4.1277 - accuracy: 0.0097 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 19s 214ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 19s 213ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 4.1277 - accuracy: 0.0118 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 4.1277 - accuracy: 0.0158 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 19s 216ms/step - loss: 4.1277 - accuracy: 0.0154 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 19s 215ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 19s 217ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 19s 213ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 19s 214ms/step - loss: 4.1277 - accuracy: 0.0118 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 19s 213ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.008}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 36s 200ms/step - loss: 6.2757 - accuracy: 0.0122 - val_loss: 5.2543 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 5.0825 - accuracy: 0.0127 - val_loss: 4.9368 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 37s 209ms/step - loss: 4.8356 - accuracy: 0.0138 - val_loss: 4.7451 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 4.6776 - accuracy: 0.0113 - val_loss: 4.6154 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 35s 202ms/step - loss: 4.5685 - accuracy: 0.0124 - val_loss: 4.5260 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 35s 202ms/step - loss: 4.4874 - accuracy: 0.0124 - val_loss: 4.4504 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 35s 199ms/step - loss: 4.4213 - accuracy: 0.0111 - val_loss: 4.3927 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 4.3697 - accuracy: 0.0111 - val_loss: 4.3467 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 4.3281 - accuracy: 0.0136 - val_loss: 4.3093 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 4.2941 - accuracy: 0.0133 - val_loss: 4.2784 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 35s 201ms/step - loss: 4.2660 - accuracy: 0.0111 - val_loss: 4.2529 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 35s 201ms/step - loss: 4.2427 - accuracy: 0.0120 - val_loss: 4.2317 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 35s 201ms/step - loss: 4.2233 - accuracy: 0.0115 - val_loss: 4.2140 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 35s 201ms/step - loss: 4.2072 - accuracy: 0.0136 - val_loss: 4.1993 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 36s 207ms/step - loss: 4.1936 - accuracy: 0.0131 - val_loss: 4.1871 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 4.1825 - accuracy: 0.0116 - val_loss: 4.1769 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 35s 201ms/step - loss: 4.1733 - accuracy: 0.0113 - val_loss: 4.1685 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 35s 202ms/step - loss: 4.1655 - accuracy: 0.0138 - val_loss: 4.1615 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 35s 202ms/step - loss: 4.1592 - accuracy: 0.0125 - val_loss: 4.1557 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 35s 201ms/step - loss: 4.1539 - accuracy: 0.0113 - val_loss: 4.1509 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.008}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 18s 197ms/step - loss: 4.5648 - accuracy: 0.0125 - val_loss: 4.1708 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 17s 197ms/step - loss: 4.1462 - accuracy: 0.0100 - val_loss: 4.1337 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 17s 196ms/step - loss: 4.1314 - accuracy: 0.0136 - val_loss: 4.1291 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 17s 198ms/step - loss: 4.1290 - accuracy: 0.0129 - val_loss: 4.1279 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 18s 200ms/step - loss: 4.1282 - accuracy: 0.0172 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 18s 200ms/step - loss: 4.1280 - accuracy: 0.0118 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 18s 200ms/step - loss: 4.1277 - accuracy: 0.0082 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 18s 200ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 4.1278 - accuracy: 0.0104 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 17s 196ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.1277 - accuracy: 0.0097 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 17s 195ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 4.1277 - accuracy: 0.0122 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.1277 - accuracy: 0.0151 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 4.1277 - accuracy: 0.0115 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 17s 192ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 32s 181ms/step - loss: 7.0238 - accuracy: 0.0120 - val_loss: 5.6613 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 28s 163ms/step - loss: 5.4336 - accuracy: 0.0124 - val_loss: 5.2430 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 29s 167ms/step - loss: 5.1103 - accuracy: 0.0131 - val_loss: 4.9916 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 30s 170ms/step - loss: 4.9013 - accuracy: 0.0127 - val_loss: 4.8173 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 4.7504 - accuracy: 0.0136 - val_loss: 4.6868 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.6348 - accuracy: 0.0122 - val_loss: 4.5845 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 28s 163ms/step - loss: 4.5430 - accuracy: 0.0145 - val_loss: 4.5025 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.4689 - accuracy: 0.0131 - val_loss: 4.4357 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.4082 - accuracy: 0.0142 - val_loss: 4.3809 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 29s 164ms/step - loss: 4.3583 - accuracy: 0.0131 - val_loss: 4.3356 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 4.3171 - accuracy: 0.0129 - val_loss: 4.2982 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 4.2830 - accuracy: 0.0136 - val_loss: 4.2673 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 29s 163ms/step - loss: 4.2548 - accuracy: 0.0140 - val_loss: 4.2417 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 28s 163ms/step - loss: 4.2315 - accuracy: 0.0106 - val_loss: 4.2205 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.2122 - accuracy: 0.0120 - val_loss: 4.2030 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.1963 - accuracy: 0.0113 - val_loss: 4.1887 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.1855 - accuracy: 0.0133 - val_loss: 4.1831 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 28s 162ms/step - loss: 4.1877 - accuracy: 0.0111 - val_loss: 4.1753 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 28s 159ms/step - loss: 4.1693 - accuracy: 0.0140 - val_loss: 4.1631 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 28s 160ms/step - loss: 4.1595 - accuracy: 0.0111 - val_loss: 4.1551 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 5, 'kernel_size2': 5, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 15s 162ms/step - loss: 4.7656 - accuracy: 0.0122 - val_loss: 4.1749 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1463 - accuracy: 0.0122 - val_loss: 4.1335 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1313 - accuracy: 0.0151 - val_loss: 4.1293 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 14s 162ms/step - loss: 4.1293 - accuracy: 0.0115 - val_loss: 4.1280 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1282 - accuracy: 0.0100 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1279 - accuracy: 0.0115 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1278 - accuracy: 0.0133 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1277 - accuracy: 0.0165 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0125 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1278 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0115 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1276 - accuracy: 0.0104 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 4.1277 - accuracy: 0.0108 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 14s 163ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 4.1277 - accuracy: 0.0097 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 64, 'drop_out_rate': 0.25, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 6.6366 - accuracy: 0.0127 - val_loss: 5.2949 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 21s 118ms/step - loss: 5.1175 - accuracy: 0.0120 - val_loss: 4.9703 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 21s 117ms/step - loss: 4.8688 - accuracy: 0.0116 - val_loss: 4.7789 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 4.7140 - accuracy: 0.0091 - val_loss: 4.6523 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 4.6048 - accuracy: 0.0127 - val_loss: 4.5647 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 4.5276 - accuracy: 0.0109 - val_loss: 4.4917 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 4.4699 - accuracy: 0.0120 - val_loss: 4.4334 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 20s 117ms/step - loss: 4.4194 - accuracy: 0.0125 - val_loss: 4.3953 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 20s 116ms/step - loss: 4.3686 - accuracy: 0.0109 - val_loss: 4.3458 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      " 54/175 [========>.....................] - ETA: 13s - loss: 4.3430 - accuracy: 0.0179"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[211], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m           loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     26\u001b[0m           metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_data_augmented, train_label_augmented_onehot, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, \n\u001b[0;32m     29\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(test_data, test_label_onehot))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluate model on validation data\u001b[39;00m\n\u001b[0;32m     32\u001b[0m accuracy_index \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39margmax(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mY:\\Anaconda3\\envs\\ML\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Define the hyperparameters and their values to search over\n",
    "param_grid = {\n",
    "    'kernel_size1': [3, 5],\n",
    "    'kernel_size2': [3, 5],\n",
    "    'regulazation_p': [0.01, 0.008, 0.012],\n",
    "    'dense_node': [64],  # [, 128, 256], dense_node search in seperate block\n",
    "    'drop_out_rate': [0.1, 0.18, 0.25],\n",
    "}\n",
    "\n",
    "\n",
    "print(\"==========started grid search============\")\n",
    "# Perform grid search\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_augmented = False\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"\\n\\n\",params , \"  Augmented\")\n",
    "    # use non-augmented data\n",
    "    model = create_model(**params)\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_data_augmented, train_label_augmented_onehot, epochs=20, \n",
    "                        validation_data=(test_data, test_label_onehot))\n",
    "    \n",
    "    # Evaluate model on validation data\n",
    "    accuracy_index = numpy.argmax(history.history['val_accuracy'])\n",
    "    accuracy = history.history['val_accuracy'][accuracy_index]\n",
    "    print(\"current best accuracy\", accuracy)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "        best_augmented = False\n",
    "        print(\"updated best\")\n",
    "        \n",
    "    \n",
    "    print(\"\\n\\n\", params , \"  Not-Augmented\")\n",
    "    # use Augmented data\n",
    "    model = create_model(**params)\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_data, train_label_onehot, epochs=20, \n",
    "                        validation_data=(test_data, test_label_onehot))\n",
    "    \n",
    "    accuracy_index = numpy.argmax(history.history['val_accuracy'])\n",
    "    accuracy = history.history['val_accuracy'][accuracy_index]\n",
    "    print(\"current best accuracy\", accuracy)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "        best_augmented = True\n",
    "        print(\"updated best\")\n",
    "\n",
    "print(\"==========finished grid search============\\n\\n\")\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_accuracy)\n",
    "print(\"Best Augmented: \", best_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dense_node': 64, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}\n",
      "Best Accuracy:  0.8080645203590393\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========started grid search============\n",
      "\n",
      "\n",
      " {'dense_node': 128, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 22s 120ms/step - loss: 6.7835 - accuracy: 0.1613 - val_loss: 5.6219 - val_accuracy: 0.2113\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 3.6987 - accuracy: 0.4466 - val_loss: 3.2205 - val_accuracy: 0.5306\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 2.6389 - accuracy: 0.6194 - val_loss: 2.6036 - val_accuracy: 0.6161\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 2.1449 - accuracy: 0.6903 - val_loss: 2.2101 - val_accuracy: 0.6581\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 22s 123ms/step - loss: 1.8228 - accuracy: 0.7376 - val_loss: 1.9822 - val_accuracy: 0.7145\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.6207 - accuracy: 0.7638 - val_loss: 1.8603 - val_accuracy: 0.7129\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 22s 123ms/step - loss: 1.4684 - accuracy: 0.7805 - val_loss: 1.7057 - val_accuracy: 0.7210\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 22s 124ms/step - loss: 1.3519 - accuracy: 0.7916 - val_loss: 1.6475 - val_accuracy: 0.7161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.2411 - accuracy: 0.8106 - val_loss: 1.5508 - val_accuracy: 0.7306\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.1915 - accuracy: 0.8174 - val_loss: 1.5760 - val_accuracy: 0.7403\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 1.1417 - accuracy: 0.8238 - val_loss: 1.5356 - val_accuracy: 0.7161\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.0590 - accuracy: 0.8362 - val_loss: 1.3866 - val_accuracy: 0.7613\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 1.0663 - accuracy: 0.8281 - val_loss: 1.4326 - val_accuracy: 0.7468\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 21s 122ms/step - loss: 0.9937 - accuracy: 0.8432 - val_loss: 1.3254 - val_accuracy: 0.7613\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 0.9562 - accuracy: 0.8534 - val_loss: 1.3428 - val_accuracy: 0.7339\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 0.9101 - accuracy: 0.8548 - val_loss: 1.2758 - val_accuracy: 0.7710\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 0.8952 - accuracy: 0.8611 - val_loss: 1.3110 - val_accuracy: 0.7532\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 21s 120ms/step - loss: 0.9263 - accuracy: 0.8539 - val_loss: 1.2917 - val_accuracy: 0.7597\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 0.8868 - accuracy: 0.8572 - val_loss: 1.2787 - val_accuracy: 0.7516\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 21s 121ms/step - loss: 0.8929 - accuracy: 0.8616 - val_loss: 1.3231 - val_accuracy: 0.7306\n",
      "current best accuracy 0.7709677219390869\n",
      "updated best\n",
      "\n",
      "\n",
      " {'dense_node': 128, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 4.7807 - accuracy: 0.0176 - val_loss: 4.1740 - val_accuracy: 0.0226\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 4.1485 - accuracy: 0.0161 - val_loss: 4.1346 - val_accuracy: 0.0419\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 13s 150ms/step - loss: 3.9601 - accuracy: 0.0556 - val_loss: 3.5026 - val_accuracy: 0.1258\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 3.3882 - accuracy: 0.1495 - val_loss: 2.9727 - val_accuracy: 0.2984\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 3.0063 - accuracy: 0.2323 - val_loss: 2.6900 - val_accuracy: 0.3435\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 2.7627 - accuracy: 0.2903 - val_loss: 2.3339 - val_accuracy: 0.4532\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 2.5923 - accuracy: 0.3247 - val_loss: 2.2629 - val_accuracy: 0.4871\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 2.4503 - accuracy: 0.3756 - val_loss: 2.1423 - val_accuracy: 0.5048\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 2.3434 - accuracy: 0.3932 - val_loss: 2.0209 - val_accuracy: 0.5323\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 2.2893 - accuracy: 0.3953 - val_loss: 1.9307 - val_accuracy: 0.5435\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 2.2490 - accuracy: 0.4147 - val_loss: 1.9557 - val_accuracy: 0.5242\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 2.1792 - accuracy: 0.4287 - val_loss: 1.8924 - val_accuracy: 0.5806\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 2.1197 - accuracy: 0.4380 - val_loss: 1.8209 - val_accuracy: 0.5806\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 2.1093 - accuracy: 0.4452 - val_loss: 1.8063 - val_accuracy: 0.5758\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 2.0595 - accuracy: 0.4616 - val_loss: 1.6974 - val_accuracy: 0.6016\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 2.0267 - accuracy: 0.4631 - val_loss: 1.6919 - val_accuracy: 0.5855\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 2.0051 - accuracy: 0.4681 - val_loss: 1.6656 - val_accuracy: 0.6403\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 1.9654 - accuracy: 0.4774 - val_loss: 1.6815 - val_accuracy: 0.6048\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 1.9449 - accuracy: 0.4903 - val_loss: 1.6189 - val_accuracy: 0.6484\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 129ms/step - loss: 1.9699 - accuracy: 0.4771 - val_loss: 1.6543 - val_accuracy: 0.6065\n",
      "current best accuracy 0.64838707447052\n",
      "\n",
      "\n",
      " {'dense_node': 128, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 7.6084 - accuracy: 0.1407 - val_loss: 6.0499 - val_accuracy: 0.2403\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 3.9971 - accuracy: 0.4518 - val_loss: 3.4971 - val_accuracy: 0.5339\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 2.7773 - accuracy: 0.6407 - val_loss: 2.6862 - val_accuracy: 0.6452\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 2.2257 - accuracy: 0.7100 - val_loss: 2.4170 - val_accuracy: 0.6500\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.8894 - accuracy: 0.7478 - val_loss: 2.1112 - val_accuracy: 0.6919\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.6656 - accuracy: 0.7772 - val_loss: 1.8918 - val_accuracy: 0.7194\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.4916 - accuracy: 0.7948 - val_loss: 1.7703 - val_accuracy: 0.7161\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.3794 - accuracy: 0.8095 - val_loss: 1.7833 - val_accuracy: 0.7161\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.2965 - accuracy: 0.8190 - val_loss: 1.5936 - val_accuracy: 0.7484\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.2115 - accuracy: 0.8281 - val_loss: 1.5864 - val_accuracy: 0.7258\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.1584 - accuracy: 0.8344 - val_loss: 1.5236 - val_accuracy: 0.7452\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.0989 - accuracy: 0.8391 - val_loss: 1.5013 - val_accuracy: 0.7242\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.0752 - accuracy: 0.8364 - val_loss: 1.4305 - val_accuracy: 0.7532\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 22s 123ms/step - loss: 1.0593 - accuracy: 0.8427 - val_loss: 1.4044 - val_accuracy: 0.7403\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.0103 - accuracy: 0.8507 - val_loss: 1.3947 - val_accuracy: 0.7597\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.9638 - accuracy: 0.8561 - val_loss: 1.3436 - val_accuracy: 0.7694\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.9541 - accuracy: 0.8597 - val_loss: 1.3774 - val_accuracy: 0.7516\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 0.9391 - accuracy: 0.8527 - val_loss: 1.3582 - val_accuracy: 0.7339\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.8998 - accuracy: 0.8631 - val_loss: 1.2906 - val_accuracy: 0.7677\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 0.8833 - accuracy: 0.8643 - val_loss: 1.3558 - val_accuracy: 0.7500\n",
      "current best accuracy 0.7693548202514648\n",
      "\n",
      "\n",
      " {'dense_node': 128, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 12s 128ms/step - loss: 4.9308 - accuracy: 0.0154 - val_loss: 4.1938 - val_accuracy: 0.0145\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.1564 - accuracy: 0.0143 - val_loss: 4.1380 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1343 - accuracy: 0.0100 - val_loss: 4.1307 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 4.1301 - accuracy: 0.0125 - val_loss: 4.1286 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.1288 - accuracy: 0.0111 - val_loss: 4.1278 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1282 - accuracy: 0.0151 - val_loss: 4.1274 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1280 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.1278 - accuracy: 0.0108 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1276 - accuracy: 0.0104 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.1277 - accuracy: 0.0147 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1277 - accuracy: 0.0111 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 11s 128ms/step - loss: 4.1277 - accuracy: 0.0129 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 11s 127ms/step - loss: 4.1277 - accuracy: 0.0118 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 11s 126ms/step - loss: 4.1277 - accuracy: 0.0143 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 256, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 25s 138ms/step - loss: 8.6055 - accuracy: 0.1918 - val_loss: 6.5284 - val_accuracy: 0.2645\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 24s 135ms/step - loss: 4.1691 - accuracy: 0.4996 - val_loss: 3.6858 - val_accuracy: 0.5290\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 24s 138ms/step - loss: 2.8934 - accuracy: 0.6663 - val_loss: 2.8818 - val_accuracy: 0.6048\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 2.2850 - accuracy: 0.7330 - val_loss: 2.4447 - val_accuracy: 0.6742\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.9065 - accuracy: 0.7683 - val_loss: 2.1742 - val_accuracy: 0.6790\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 1.6618 - accuracy: 0.7896 - val_loss: 2.0040 - val_accuracy: 0.6919\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 24s 135ms/step - loss: 1.4965 - accuracy: 0.8095 - val_loss: 1.8818 - val_accuracy: 0.7129\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 1.3536 - accuracy: 0.8235 - val_loss: 1.7931 - val_accuracy: 0.6984\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 1.2684 - accuracy: 0.8375 - val_loss: 1.7143 - val_accuracy: 0.7097\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 1.2268 - accuracy: 0.8409 - val_loss: 1.5817 - val_accuracy: 0.7371\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.1469 - accuracy: 0.8466 - val_loss: 1.5800 - val_accuracy: 0.7355\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 24s 135ms/step - loss: 1.0781 - accuracy: 0.8611 - val_loss: 1.5855 - val_accuracy: 0.7290\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.0896 - accuracy: 0.8550 - val_loss: 1.4568 - val_accuracy: 0.7403\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 24s 135ms/step - loss: 1.0104 - accuracy: 0.8654 - val_loss: 1.4332 - val_accuracy: 0.7613\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 24s 138ms/step - loss: 0.9848 - accuracy: 0.8683 - val_loss: 1.4188 - val_accuracy: 0.7274\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 24s 135ms/step - loss: 0.9493 - accuracy: 0.8708 - val_loss: 1.4830 - val_accuracy: 0.7210\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 0.9174 - accuracy: 0.8710 - val_loss: 1.3981 - val_accuracy: 0.7355\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 0.9244 - accuracy: 0.8692 - val_loss: 1.3075 - val_accuracy: 0.7677\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 0.9302 - accuracy: 0.8799 - val_loss: 1.4034 - val_accuracy: 0.7548\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 0.8795 - accuracy: 0.8833 - val_loss: 1.2792 - val_accuracy: 0.7742\n",
      "current best accuracy 0.774193525314331\n",
      "updated best\n",
      "\n",
      "\n",
      " {'dense_node': 256, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.01}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 13s 141ms/step - loss: 5.0327 - accuracy: 0.0140 - val_loss: 4.1792 - val_accuracy: 0.0161\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 4.1514 - accuracy: 0.0165 - val_loss: 4.1369 - val_accuracy: 0.0161\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 4.1339 - accuracy: 0.0125 - val_loss: 4.1309 - val_accuracy: 0.0161\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 13s 145ms/step - loss: 4.1305 - accuracy: 0.0118 - val_loss: 4.1290 - val_accuracy: 0.0161\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 13s 143ms/step - loss: 4.1293 - accuracy: 0.0115 - val_loss: 4.1282 - val_accuracy: 0.0161\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 4.1286 - accuracy: 0.0154 - val_loss: 4.1277 - val_accuracy: 0.0161\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 4.1282 - accuracy: 0.0115 - val_loss: 4.1275 - val_accuracy: 0.0161\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 4.1280 - accuracy: 0.0136 - val_loss: 4.1273 - val_accuracy: 0.0161\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 4.1278 - accuracy: 0.0108 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 4.1278 - accuracy: 0.0108 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 4.1277 - accuracy: 0.0161 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 4.1277 - accuracy: 0.0104 - val_loss: 4.1272 - val_accuracy: 0.0161\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 4.1277 - accuracy: 0.0118 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 4.1277 - accuracy: 0.0115 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 13s 143ms/step - loss: 4.1277 - accuracy: 0.0140 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 4.1277 - accuracy: 0.0136 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 4.1277 - accuracy: 0.0133 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 4.1277 - accuracy: 0.0104 - val_loss: 4.1271 - val_accuracy: 0.0161\n",
      "current best accuracy 0.016129031777381897\n",
      "\n",
      "\n",
      " {'dense_node': 256, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Augmented\n",
      "Epoch 1/20\n",
      "175/175 [==============================] - 25s 137ms/step - loss: 8.8191 - accuracy: 0.1869 - val_loss: 6.9834 - val_accuracy: 0.1774\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 24s 138ms/step - loss: 4.5830 - accuracy: 0.4851 - val_loss: 4.0478 - val_accuracy: 0.5194\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 24s 138ms/step - loss: 3.1426 - accuracy: 0.6461 - val_loss: 3.1003 - val_accuracy: 0.6016\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 2.4287 - accuracy: 0.7159 - val_loss: 2.5383 - val_accuracy: 0.6710\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.9904 - accuracy: 0.7471 - val_loss: 2.2577 - val_accuracy: 0.6629\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.7263 - accuracy: 0.7717 - val_loss: 2.0684 - val_accuracy: 0.6484\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.5565 - accuracy: 0.7812 - val_loss: 1.9151 - val_accuracy: 0.6855\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.3769 - accuracy: 0.8091 - val_loss: 1.6837 - val_accuracy: 0.7210\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.2604 - accuracy: 0.8133 - val_loss: 1.7236 - val_accuracy: 0.7129\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 24s 138ms/step - loss: 1.1908 - accuracy: 0.8235 - val_loss: 1.6388 - val_accuracy: 0.7194\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.1385 - accuracy: 0.8285 - val_loss: 1.5541 - val_accuracy: 0.7339\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.0836 - accuracy: 0.8367 - val_loss: 1.4408 - val_accuracy: 0.7677\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 1.0364 - accuracy: 0.8486 - val_loss: 1.4345 - val_accuracy: 0.7435\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 1.0117 - accuracy: 0.8523 - val_loss: 1.3686 - val_accuracy: 0.7548\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 1.0154 - accuracy: 0.8504 - val_loss: 1.4214 - val_accuracy: 0.7452\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 0.9314 - accuracy: 0.8543 - val_loss: 1.3622 - val_accuracy: 0.7516\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 0.9561 - accuracy: 0.8572 - val_loss: 1.4058 - val_accuracy: 0.7435\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 0.9148 - accuracy: 0.8670 - val_loss: 1.3685 - val_accuracy: 0.7468\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 24s 136ms/step - loss: 0.9427 - accuracy: 0.8541 - val_loss: 1.3363 - val_accuracy: 0.7661\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 0.9188 - accuracy: 0.8629 - val_loss: 1.3300 - val_accuracy: 0.7565\n",
      "current best accuracy 0.7677419185638428\n",
      "\n",
      "\n",
      " {'dense_node': 256, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}   Not-Augmented\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 13s 141ms/step - loss: 4.9352 - accuracy: 0.0738 - val_loss: 3.4053 - val_accuracy: 0.2661\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 2.8881 - accuracy: 0.4011 - val_loss: 2.3704 - val_accuracy: 0.5371\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 2.1523 - accuracy: 0.5778 - val_loss: 2.0178 - val_accuracy: 0.6371\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 12s 142ms/step - loss: 1.7910 - accuracy: 0.6760 - val_loss: 1.7868 - val_accuracy: 0.6887\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.5959 - accuracy: 0.7194 - val_loss: 1.6289 - val_accuracy: 0.7290\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 1.4307 - accuracy: 0.7516 - val_loss: 1.5833 - val_accuracy: 0.7194\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 1.2575 - accuracy: 0.8036 - val_loss: 1.5786 - val_accuracy: 0.7290\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2354 - accuracy: 0.8097 - val_loss: 1.4933 - val_accuracy: 0.7274\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.1260 - accuracy: 0.8215 - val_loss: 1.3756 - val_accuracy: 0.7548\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.1089 - accuracy: 0.8240 - val_loss: 1.3477 - val_accuracy: 0.7742\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 1.0470 - accuracy: 0.8405 - val_loss: 1.3591 - val_accuracy: 0.7694\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 1.0127 - accuracy: 0.8545 - val_loss: 1.2904 - val_accuracy: 0.7919\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.9332 - accuracy: 0.8767 - val_loss: 1.2869 - val_accuracy: 0.7694\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.9156 - accuracy: 0.8746 - val_loss: 1.3209 - val_accuracy: 0.7500\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.9609 - accuracy: 0.8595 - val_loss: 1.2617 - val_accuracy: 0.7790\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 0.9137 - accuracy: 0.8781 - val_loss: 1.2379 - val_accuracy: 0.7806\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.8735 - accuracy: 0.8846 - val_loss: 1.2311 - val_accuracy: 0.7806\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 0.8625 - accuracy: 0.8832 - val_loss: 1.2298 - val_accuracy: 0.7903\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 0.8405 - accuracy: 0.8943 - val_loss: 1.2011 - val_accuracy: 0.7984\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 12s 141ms/step - loss: 0.8333 - accuracy: 0.8860 - val_loss: 1.2021 - val_accuracy: 0.7952\n",
      "current best accuracy 0.7983871102333069\n",
      "updated best\n",
      "==========finished grid search============\n",
      "\n",
      "\n",
      "Best Parameters:  {'dense_node': 256, 'drop_out_rate': 0.18, 'kernel_size1': 3, 'kernel_size2': 3, 'regulazation_p': 0.012}\n",
      "Best Accuracy:  0.7983871102333069\n",
      "Best Augmented:  True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Define the hyperparameters and their values to search over\n",
    "param_grid = {\n",
    "    'kernel_size1': [3],\n",
    "    'kernel_size2': [3],\n",
    "    'regulazation_p': [0.01, 0.012],\n",
    "    'dense_node': [128, 256], # dense_node search on 128, 256 on strinked scope\n",
    "    'drop_out_rate': [0.18],\n",
    "}\n",
    "\n",
    "\n",
    "print(\"==========started grid search============\")\n",
    "# Perform grid search\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "best_augmented = False\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(\"\\n\\n\",params , \"  Augmented\")\n",
    "    # use non-augmented data\n",
    "    model = create_model(**params)\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_data_augmented, train_label_augmented_onehot, epochs=20, \n",
    "                        validation_data=(test_data, test_label_onehot))\n",
    "    \n",
    "    # Evaluate model on validation data\n",
    "    accuracy_index = numpy.argmax(history.history['val_accuracy'])\n",
    "    accuracy = history.history['val_accuracy'][accuracy_index]\n",
    "    print(\"current best accuracy\", accuracy)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "        best_augmented = False\n",
    "        print(\"updated best\")\n",
    "        \n",
    "    \n",
    "    print(\"\\n\\n\", params , \"  Not-Augmented\")\n",
    "    # use Augmented data\n",
    "    model = create_model(**params)\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_data, train_label_onehot, epochs=20, \n",
    "                        validation_data=(test_data, test_label_onehot))\n",
    "    \n",
    "    accuracy_index = numpy.argmax(history.history['val_accuracy'])\n",
    "    accuracy = history.history['val_accuracy'][accuracy_index]\n",
    "    print(\"current best accuracy\", accuracy)\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = params\n",
    "        best_augmented = True\n",
    "        print(\"updated best\")\n",
    "\n",
    "print(\"==========finished grid search============\\n\\n\")\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Accuracy: \", best_accuracy)\n",
    "print(\"Best Augmented: \", best_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
